{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-14T11:21:23.648078Z","iopub.execute_input":"2023-08-14T11:21:23.648523Z","iopub.status.idle":"2023-08-14T11:21:23.664117Z","shell.execute_reply.started":"2023-08-14T11:21:23.648494Z","shell.execute_reply":"2023-08-14T11:21:23.662070Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport argparse, random, copy\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nfrom torchvision import transforms as T\nfrom torch.optim.lr_scheduler import StepLR\n\n\nclass SiameseNetwork(nn.Module):\n    \"\"\"\n        Siamese network for image similarity estimation.\n        The network is composed of two identical networks, one for each input.\n        The output of each network is concatenated and passed to a linear layer. \n        The output of the linear layer passed through a sigmoid function.\n        `\"FaceNet\" <https://arxiv.org/pdf/1503.03832.pdf>`_ is a variant of the Siamese network.\n        This implementation varies from FaceNet as we use the `ResNet-18` model from\n        `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_ as our feature extractor.\n        In addition, we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n    \"\"\"\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        # get resnet model\n        self.resnet = torchvision.models.resnet18(weights=None)\n\n        # over-write the first conv layer to be able to read MNIST images\n        # as resnet18 reads (3,x,x) where 3 is RGB channels\n        # whereas MNIST has (1,x,x) where 1 is a gray-scale channel\n        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.fc_in_features = self.resnet.fc.in_features\n        \n        # remove the last layer of resnet18 (linear layer which is before avgpool layer)\n        self.resnet = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))\n\n        # add linear layers to compare between the features of the two images\n        self.fc = nn.Sequential(\n            nn.Linear(self.fc_in_features * 2, 256),\n            nn.ReLU(inplace=True),\n            nn.Linear(256, 1),\n        )\n\n        self.sigmoid = nn.Sigmoid()\n\n        # initialize the weights\n        self.resnet.apply(self.init_weights)\n        self.fc.apply(self.init_weights)\n        \n    def init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            torch.nn.init.xavier_uniform_(m.weight)\n            m.bias.data.fill_(0.01)\n\n    def forward_once(self, x):\n        output = self.resnet(x)\n        output = output.view(output.size()[0], -1)\n        return output\n\n    def forward(self, input1, input2):\n        # get two images' features\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n\n        # concatenate both images' features\n        output = torch.cat((output1, output2), 1)\n\n        # pass the concatenation to the linear layers\n        output = self.fc(output)\n\n        # pass the out of the linear layers to sigmoid layer\n        output = self.sigmoid(output)\n        \n        return output\n\nclass APP_MATCHER(Dataset):\n    def __init__(self, root, train, download=False):\n        super(APP_MATCHER, self).__init__()\n\n        # get MNIST dataset\n        self.dataset = datasets.MNIST(root, train=train, download=download)\n        \n        # as `self.dataset.data`'s shape is (Nx28x28), where N is the number of\n        # examples in MNIST dataset, a single example has the dimensions of\n        # (28x28) for (WxH), where W and H are the width and the height of the image. \n        # However, every example should have (CxWxH) dimensions where C is the number \n        # of channels to be passed to the network. As MNIST contains gray-scale images, \n        # we add an additional dimension to corresponds to the number of channels.\n        self.data = self.dataset.data.unsqueeze(1).clone()\n\n        self.group_examples()\n\n    def group_examples(self):\n        \"\"\"\n            To ease the accessibility of data based on the class, we will use `group_examples` to group \n            examples based on class. \n            \n            Every key in `grouped_examples` corresponds to a class in MNIST dataset. For every key in \n            `grouped_examples`, every value will conform to all of the indices for the MNIST \n            dataset examples that correspond to that key.\n        \"\"\"\n\n        # get the targets from MNIST dataset\n        np_arr = np.array(self.dataset.targets.clone())\n        \n        # group examples based on class\n        self.grouped_examples = {}\n        for i in range(0,10):\n            self.grouped_examples[i] = np.where((np_arr==i))[0]\n    \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, index):\n        \"\"\"\n            For every example, we will select two images. There are two cases, \n            positive and negative examples. For positive examples, we will have two \n            images from the same class. For negative examples, we will have two images \n            from different classes.\n\n            Given an index, if the index is even, we will pick the second image from the same class, \n            but it won't be the same image we chose for the first class. This is used to ensure the positive\n            example isn't trivial as the network would easily distinguish the similarity between same images. However,\n            if the network were given two different images from the same class, the network will need to learn \n            the similarity between two different images representing the same class. If the index is odd, we will \n            pick the second image from a different class than the first image.\n        \"\"\"\n\n        # pick some random class for the first image\n        selected_class = random.randint(0, 9)\n\n        # pick a random index for the first image in the grouped indices based of the label\n        # of the class\n        random_index_1 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n        \n        # pick the index to get the first image\n        index_1 = self.grouped_examples[selected_class][random_index_1]\n\n        # get the first image\n        image_1 = self.data[index_1].clone().float()\n\n        # same class\n        if index % 2 == 0:\n            # pick a random index for the second image\n            random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n            \n            # ensure that the index of the second image isn't the same as the first image\n            while random_index_2 == random_index_1:\n                random_index_2 = random.randint(0, self.grouped_examples[selected_class].shape[0]-1)\n            \n            # pick the index to get the second image\n            index_2 = self.grouped_examples[selected_class][random_index_2]\n\n            # get the second image\n            image_2 = self.data[index_2].clone().float()\n\n            # set the label for this example to be positive (1)\n            target = torch.tensor(1, dtype=torch.float)\n        \n        # different class\n        else:\n            # pick a random class\n            other_selected_class = random.randint(0, 9)\n\n            # ensure that the class of the second image isn't the same as the first image\n            while other_selected_class == selected_class:\n                other_selected_class = random.randint(0, 9)\n\n            \n            # pick a random index for the second image in the grouped indices based of the label\n            # of the class\n            random_index_2 = random.randint(0, self.grouped_examples[other_selected_class].shape[0]-1)\n\n            # pick the index to get the second image\n            index_2 = self.grouped_examples[other_selected_class][random_index_2]\n\n            # get the second image\n            image_2 = self.data[index_2].clone().float()\n\n            # set the label for this example to be negative (0)\n            target = torch.tensor(0, dtype=torch.float)\n\n        return image_1, image_2, target\n\n\ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n\n    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n    criterion = nn.BCELoss()\n\n    for batch_idx, (images_1, images_2, targets) in enumerate(train_loader):\n        images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(images_1, images_2).squeeze()\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(images_1), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n            if args.dry_run:\n                break\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.\n    criterion = nn.BCELoss()\n\n    with torch.no_grad():\n        for (images_1, images_2, targets) in test_loader:\n            images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)\n            outputs = model(images_1, images_2).squeeze()\n            test_loss += criterion(outputs, targets).sum().item()  # sum up batch loss\n            pred = torch.where(outputs > 0.5, 1, 0)  # get the index of the max log-probability\n            correct += pred.eq(targets.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n\n    # for the 1st epoch, the average loss is 0.0001 and the accuracy 97-98%\n    # using default settings. After completing the 10th epoch, the average\n    # loss is 0.0000 and the accuracy 99.5-100% using default settings.\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n\n\ndef main():\n    # Training settings\n    parser = argparse.ArgumentParser(description='PyTorch Siamese network Example')\n    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                        help='input batch size for training (default: 64)')\n    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n                        help='input batch size for testing (default: 1000)')\n    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n                        help='number of epochs to train (default: 14)')\n    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n                        help='learning rate (default: 1.0)')\n    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n                        help='Learning rate step gamma (default: 0.7)')\n    parser.add_argument('--no-cuda', action='store_true', default=False,\n                        help='disables CUDA training')\n    parser.add_argument('--no-mps', action='store_true', default=False,\n                        help='disables macOS GPU training')\n    parser.add_argument('--dry-run', action='store_true', default=False,\n                        help='quickly check a single pass')\n    parser.add_argument('--seed', type=int, default=1, metavar='S',\n                        help='random seed (default: 1)')\n    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                        help='how many batches to wait before logging training status')\n    parser.add_argument('--save-model', action='store_true', default=False,\n                        help='For Saving the current Model')\n    args,_ = parser.parse_known_args()\n    \n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n    use_mps = not args.no_mps and torch.backends.mps.is_available()\n\n    torch.manual_seed(args.seed)\n\n    if use_cuda:\n        device = torch.device(\"cuda\")\n    elif use_mps:\n        device = torch.device(\"mps\")\n    else:\n        device = torch.device(\"cpu\")\n\n    train_kwargs = {'batch_size': args.batch_size}\n    test_kwargs = {'batch_size': args.test_batch_size}\n    if use_cuda:\n        cuda_kwargs = {'num_workers': 1,\n                       'pin_memory': True,\n                       'shuffle': True}\n        train_kwargs.update(cuda_kwargs)\n        test_kwargs.update(cuda_kwargs)\n\n    train_dataset = APP_MATCHER('../data', train=True, download=True)\n    test_dataset = APP_MATCHER('../data', train=False)\n    train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)\n    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n\n    model = SiameseNetwork().to(device)\n    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n\n    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch)\n        test(model, device, test_loader)\n        scheduler.step()\n\n    if args.save_model:\n        torch.save(model.state_dict(), \"siamese_network.pt\")\n\n\nif __name__ == '__main__':\n    main()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T11:21:24.889278Z","iopub.execute_input":"2023-08-14T11:21:24.889734Z","iopub.status.idle":"2023-08-14T11:28:49.858705Z","shell.execute_reply.started":"2023-08-14T11:21:24.889694Z","shell.execute_reply":"2023-08-14T11:28:49.857571Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 106625166.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 118993805.33it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 1648877/1648877 [00:00<00:00, 27153194.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 10702544.25it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.846423\nTrain Epoch: 1 [640/60000 (1%)]\tLoss: 0.753666\nTrain Epoch: 1 [1280/60000 (2%)]\tLoss: 0.614969\nTrain Epoch: 1 [1920/60000 (3%)]\tLoss: 0.652623\nTrain Epoch: 1 [2560/60000 (4%)]\tLoss: 0.555110\nTrain Epoch: 1 [3200/60000 (5%)]\tLoss: 0.471190\nTrain Epoch: 1 [3840/60000 (6%)]\tLoss: 0.576340\nTrain Epoch: 1 [4480/60000 (7%)]\tLoss: 0.556684\nTrain Epoch: 1 [5120/60000 (9%)]\tLoss: 0.432714\nTrain Epoch: 1 [5760/60000 (10%)]\tLoss: 0.388020\nTrain Epoch: 1 [6400/60000 (11%)]\tLoss: 0.291225\nTrain Epoch: 1 [7040/60000 (12%)]\tLoss: 0.351350\nTrain Epoch: 1 [7680/60000 (13%)]\tLoss: 0.307590\nTrain Epoch: 1 [8320/60000 (14%)]\tLoss: 0.473043\nTrain Epoch: 1 [8960/60000 (15%)]\tLoss: 0.219865\nTrain Epoch: 1 [9600/60000 (16%)]\tLoss: 0.292904\nTrain Epoch: 1 [10240/60000 (17%)]\tLoss: 0.216487\nTrain Epoch: 1 [10880/60000 (18%)]\tLoss: 0.221889\nTrain Epoch: 1 [11520/60000 (19%)]\tLoss: 0.334909\nTrain Epoch: 1 [12160/60000 (20%)]\tLoss: 0.373598\nTrain Epoch: 1 [12800/60000 (21%)]\tLoss: 0.213643\nTrain Epoch: 1 [13440/60000 (22%)]\tLoss: 0.229263\nTrain Epoch: 1 [14080/60000 (23%)]\tLoss: 0.199446\nTrain Epoch: 1 [14720/60000 (25%)]\tLoss: 0.288337\nTrain Epoch: 1 [15360/60000 (26%)]\tLoss: 0.084320\nTrain Epoch: 1 [16000/60000 (27%)]\tLoss: 0.149564\nTrain Epoch: 1 [16640/60000 (28%)]\tLoss: 0.223966\nTrain Epoch: 1 [17280/60000 (29%)]\tLoss: 0.197438\nTrain Epoch: 1 [17920/60000 (30%)]\tLoss: 0.170282\nTrain Epoch: 1 [18560/60000 (31%)]\tLoss: 0.306260\nTrain Epoch: 1 [19200/60000 (32%)]\tLoss: 0.187442\nTrain Epoch: 1 [19840/60000 (33%)]\tLoss: 0.142759\nTrain Epoch: 1 [20480/60000 (34%)]\tLoss: 0.120345\nTrain Epoch: 1 [21120/60000 (35%)]\tLoss: 0.136128\nTrain Epoch: 1 [21760/60000 (36%)]\tLoss: 0.149440\nTrain Epoch: 1 [22400/60000 (37%)]\tLoss: 0.094394\nTrain Epoch: 1 [23040/60000 (38%)]\tLoss: 0.261261\nTrain Epoch: 1 [23680/60000 (39%)]\tLoss: 0.070737\nTrain Epoch: 1 [24320/60000 (41%)]\tLoss: 0.305794\nTrain Epoch: 1 [24960/60000 (42%)]\tLoss: 0.058035\nTrain Epoch: 1 [25600/60000 (43%)]\tLoss: 0.150876\nTrain Epoch: 1 [26240/60000 (44%)]\tLoss: 0.207614\nTrain Epoch: 1 [26880/60000 (45%)]\tLoss: 0.076399\nTrain Epoch: 1 [27520/60000 (46%)]\tLoss: 0.173872\nTrain Epoch: 1 [28160/60000 (47%)]\tLoss: 0.030963\nTrain Epoch: 1 [28800/60000 (48%)]\tLoss: 0.068628\nTrain Epoch: 1 [29440/60000 (49%)]\tLoss: 0.149831\nTrain Epoch: 1 [30080/60000 (50%)]\tLoss: 0.163460\nTrain Epoch: 1 [30720/60000 (51%)]\tLoss: 0.053946\nTrain Epoch: 1 [31360/60000 (52%)]\tLoss: 0.083139\nTrain Epoch: 1 [32000/60000 (53%)]\tLoss: 0.058654\nTrain Epoch: 1 [32640/60000 (54%)]\tLoss: 0.158633\nTrain Epoch: 1 [33280/60000 (55%)]\tLoss: 0.037805\nTrain Epoch: 1 [33920/60000 (57%)]\tLoss: 0.120922\nTrain Epoch: 1 [34560/60000 (58%)]\tLoss: 0.108924\nTrain Epoch: 1 [35200/60000 (59%)]\tLoss: 0.155200\nTrain Epoch: 1 [35840/60000 (60%)]\tLoss: 0.290006\nTrain Epoch: 1 [36480/60000 (61%)]\tLoss: 0.042165\nTrain Epoch: 1 [37120/60000 (62%)]\tLoss: 0.187087\nTrain Epoch: 1 [37760/60000 (63%)]\tLoss: 0.117504\nTrain Epoch: 1 [38400/60000 (64%)]\tLoss: 0.091800\nTrain Epoch: 1 [39040/60000 (65%)]\tLoss: 0.017103\nTrain Epoch: 1 [39680/60000 (66%)]\tLoss: 0.050375\nTrain Epoch: 1 [40320/60000 (67%)]\tLoss: 0.055223\nTrain Epoch: 1 [40960/60000 (68%)]\tLoss: 0.231086\nTrain Epoch: 1 [41600/60000 (69%)]\tLoss: 0.057306\nTrain Epoch: 1 [42240/60000 (70%)]\tLoss: 0.272514\nTrain Epoch: 1 [42880/60000 (71%)]\tLoss: 0.087302\nTrain Epoch: 1 [43520/60000 (72%)]\tLoss: 0.109423\nTrain Epoch: 1 [44160/60000 (74%)]\tLoss: 0.047120\nTrain Epoch: 1 [44800/60000 (75%)]\tLoss: 0.021642\nTrain Epoch: 1 [45440/60000 (76%)]\tLoss: 0.144437\nTrain Epoch: 1 [46080/60000 (77%)]\tLoss: 0.068430\nTrain Epoch: 1 [46720/60000 (78%)]\tLoss: 0.199408\nTrain Epoch: 1 [47360/60000 (79%)]\tLoss: 0.045718\nTrain Epoch: 1 [48000/60000 (80%)]\tLoss: 0.068174\nTrain Epoch: 1 [48640/60000 (81%)]\tLoss: 0.012962\nTrain Epoch: 1 [49280/60000 (82%)]\tLoss: 0.020631\nTrain Epoch: 1 [49920/60000 (83%)]\tLoss: 0.086316\nTrain Epoch: 1 [50560/60000 (84%)]\tLoss: 0.125271\nTrain Epoch: 1 [51200/60000 (85%)]\tLoss: 0.162905\nTrain Epoch: 1 [51840/60000 (86%)]\tLoss: 0.082050\nTrain Epoch: 1 [52480/60000 (87%)]\tLoss: 0.114781\nTrain Epoch: 1 [53120/60000 (88%)]\tLoss: 0.110893\nTrain Epoch: 1 [53760/60000 (90%)]\tLoss: 0.025014\nTrain Epoch: 1 [54400/60000 (91%)]\tLoss: 0.125769\nTrain Epoch: 1 [55040/60000 (92%)]\tLoss: 0.014154\nTrain Epoch: 1 [55680/60000 (93%)]\tLoss: 0.012994\nTrain Epoch: 1 [56320/60000 (94%)]\tLoss: 0.195458\nTrain Epoch: 1 [56960/60000 (95%)]\tLoss: 0.036927\nTrain Epoch: 1 [57600/60000 (96%)]\tLoss: 0.265441\nTrain Epoch: 1 [58240/60000 (97%)]\tLoss: 0.042128\nTrain Epoch: 1 [58880/60000 (98%)]\tLoss: 0.015729\nTrain Epoch: 1 [59520/60000 (99%)]\tLoss: 0.047061\n\nTest set: Average loss: 0.0001, Accuracy: 9776/10000 (98%)\n\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 0.034066\nTrain Epoch: 2 [640/60000 (1%)]\tLoss: 0.024150\nTrain Epoch: 2 [1280/60000 (2%)]\tLoss: 0.011419\nTrain Epoch: 2 [1920/60000 (3%)]\tLoss: 0.023607\nTrain Epoch: 2 [2560/60000 (4%)]\tLoss: 0.007968\nTrain Epoch: 2 [3200/60000 (5%)]\tLoss: 0.035980\nTrain Epoch: 2 [3840/60000 (6%)]\tLoss: 0.043694\nTrain Epoch: 2 [4480/60000 (7%)]\tLoss: 0.116741\nTrain Epoch: 2 [5120/60000 (9%)]\tLoss: 0.021994\nTrain Epoch: 2 [5760/60000 (10%)]\tLoss: 0.137998\nTrain Epoch: 2 [6400/60000 (11%)]\tLoss: 0.041963\nTrain Epoch: 2 [7040/60000 (12%)]\tLoss: 0.125733\nTrain Epoch: 2 [7680/60000 (13%)]\tLoss: 0.235669\nTrain Epoch: 2 [8320/60000 (14%)]\tLoss: 0.086325\nTrain Epoch: 2 [8960/60000 (15%)]\tLoss: 0.124896\nTrain Epoch: 2 [9600/60000 (16%)]\tLoss: 0.127473\nTrain Epoch: 2 [10240/60000 (17%)]\tLoss: 0.037977\nTrain Epoch: 2 [10880/60000 (18%)]\tLoss: 0.058042\nTrain Epoch: 2 [11520/60000 (19%)]\tLoss: 0.008584\nTrain Epoch: 2 [12160/60000 (20%)]\tLoss: 0.102352\nTrain Epoch: 2 [12800/60000 (21%)]\tLoss: 0.036140\nTrain Epoch: 2 [13440/60000 (22%)]\tLoss: 0.025417\nTrain Epoch: 2 [14080/60000 (23%)]\tLoss: 0.066917\nTrain Epoch: 2 [14720/60000 (25%)]\tLoss: 0.005323\nTrain Epoch: 2 [15360/60000 (26%)]\tLoss: 0.004845\nTrain Epoch: 2 [16000/60000 (27%)]\tLoss: 0.027469\nTrain Epoch: 2 [16640/60000 (28%)]\tLoss: 0.006241\nTrain Epoch: 2 [17280/60000 (29%)]\tLoss: 0.018954\nTrain Epoch: 2 [17920/60000 (30%)]\tLoss: 0.014734\nTrain Epoch: 2 [18560/60000 (31%)]\tLoss: 0.002981\nTrain Epoch: 2 [19200/60000 (32%)]\tLoss: 0.030382\nTrain Epoch: 2 [19840/60000 (33%)]\tLoss: 0.137977\nTrain Epoch: 2 [20480/60000 (34%)]\tLoss: 0.025496\nTrain Epoch: 2 [21120/60000 (35%)]\tLoss: 0.003165\nTrain Epoch: 2 [21760/60000 (36%)]\tLoss: 0.006273\nTrain Epoch: 2 [22400/60000 (37%)]\tLoss: 0.008694\nTrain Epoch: 2 [23040/60000 (38%)]\tLoss: 0.014396\nTrain Epoch: 2 [23680/60000 (39%)]\tLoss: 0.004135\nTrain Epoch: 2 [24320/60000 (41%)]\tLoss: 0.043153\nTrain Epoch: 2 [24960/60000 (42%)]\tLoss: 0.005879\nTrain Epoch: 2 [25600/60000 (43%)]\tLoss: 0.125689\nTrain Epoch: 2 [26240/60000 (44%)]\tLoss: 0.026983\nTrain Epoch: 2 [26880/60000 (45%)]\tLoss: 0.003406\nTrain Epoch: 2 [27520/60000 (46%)]\tLoss: 0.071236\nTrain Epoch: 2 [28160/60000 (47%)]\tLoss: 0.042853\nTrain Epoch: 2 [28800/60000 (48%)]\tLoss: 0.017743\nTrain Epoch: 2 [29440/60000 (49%)]\tLoss: 0.076178\nTrain Epoch: 2 [30080/60000 (50%)]\tLoss: 0.021660\nTrain Epoch: 2 [30720/60000 (51%)]\tLoss: 0.060774\nTrain Epoch: 2 [31360/60000 (52%)]\tLoss: 0.125017\nTrain Epoch: 2 [32000/60000 (53%)]\tLoss: 0.003318\nTrain Epoch: 2 [32640/60000 (54%)]\tLoss: 0.001340\nTrain Epoch: 2 [33280/60000 (55%)]\tLoss: 0.141296\nTrain Epoch: 2 [33920/60000 (57%)]\tLoss: 0.014249\nTrain Epoch: 2 [34560/60000 (58%)]\tLoss: 0.010919\nTrain Epoch: 2 [35200/60000 (59%)]\tLoss: 0.030838\nTrain Epoch: 2 [35840/60000 (60%)]\tLoss: 0.023294\nTrain Epoch: 2 [36480/60000 (61%)]\tLoss: 0.052775\nTrain Epoch: 2 [37120/60000 (62%)]\tLoss: 0.006793\nTrain Epoch: 2 [37760/60000 (63%)]\tLoss: 0.079356\nTrain Epoch: 2 [38400/60000 (64%)]\tLoss: 0.119958\nTrain Epoch: 2 [39040/60000 (65%)]\tLoss: 0.018417\nTrain Epoch: 2 [39680/60000 (66%)]\tLoss: 0.018873\nTrain Epoch: 2 [40320/60000 (67%)]\tLoss: 0.086797\nTrain Epoch: 2 [40960/60000 (68%)]\tLoss: 0.029261\nTrain Epoch: 2 [41600/60000 (69%)]\tLoss: 0.054524\nTrain Epoch: 2 [42240/60000 (70%)]\tLoss: 0.019779\nTrain Epoch: 2 [42880/60000 (71%)]\tLoss: 0.067466\nTrain Epoch: 2 [43520/60000 (72%)]\tLoss: 0.022494\nTrain Epoch: 2 [44160/60000 (74%)]\tLoss: 0.030198\nTrain Epoch: 2 [44800/60000 (75%)]\tLoss: 0.010183\nTrain Epoch: 2 [45440/60000 (76%)]\tLoss: 0.047655\nTrain Epoch: 2 [46080/60000 (77%)]\tLoss: 0.031348\nTrain Epoch: 2 [46720/60000 (78%)]\tLoss: 0.029736\nTrain Epoch: 2 [47360/60000 (79%)]\tLoss: 0.106450\nTrain Epoch: 2 [48000/60000 (80%)]\tLoss: 0.015953\nTrain Epoch: 2 [48640/60000 (81%)]\tLoss: 0.019358\nTrain Epoch: 2 [49280/60000 (82%)]\tLoss: 0.006208\nTrain Epoch: 2 [49920/60000 (83%)]\tLoss: 0.052412\nTrain Epoch: 2 [50560/60000 (84%)]\tLoss: 0.156722\nTrain Epoch: 2 [51200/60000 (85%)]\tLoss: 0.022097\nTrain Epoch: 2 [51840/60000 (86%)]\tLoss: 0.044692\nTrain Epoch: 2 [52480/60000 (87%)]\tLoss: 0.013065\nTrain Epoch: 2 [53120/60000 (88%)]\tLoss: 0.021910\nTrain Epoch: 2 [53760/60000 (90%)]\tLoss: 0.036956\nTrain Epoch: 2 [54400/60000 (91%)]\tLoss: 0.020859\nTrain Epoch: 2 [55040/60000 (92%)]\tLoss: 0.005087\nTrain Epoch: 2 [55680/60000 (93%)]\tLoss: 0.005696\nTrain Epoch: 2 [56320/60000 (94%)]\tLoss: 0.099045\nTrain Epoch: 2 [56960/60000 (95%)]\tLoss: 0.146924\nTrain Epoch: 2 [57600/60000 (96%)]\tLoss: 0.006837\nTrain Epoch: 2 [58240/60000 (97%)]\tLoss: 0.003171\nTrain Epoch: 2 [58880/60000 (98%)]\tLoss: 0.025236\nTrain Epoch: 2 [59520/60000 (99%)]\tLoss: 0.023018\n\nTest set: Average loss: 0.0000, Accuracy: 9866/10000 (99%)\n\nTrain Epoch: 3 [0/60000 (0%)]\tLoss: 0.053895\nTrain Epoch: 3 [640/60000 (1%)]\tLoss: 0.058807\nTrain Epoch: 3 [1280/60000 (2%)]\tLoss: 0.047182\nTrain Epoch: 3 [1920/60000 (3%)]\tLoss: 0.012604\nTrain Epoch: 3 [2560/60000 (4%)]\tLoss: 0.011849\nTrain Epoch: 3 [3200/60000 (5%)]\tLoss: 0.013754\nTrain Epoch: 3 [3840/60000 (6%)]\tLoss: 0.065585\nTrain Epoch: 3 [4480/60000 (7%)]\tLoss: 0.009353\nTrain Epoch: 3 [5120/60000 (9%)]\tLoss: 0.001237\nTrain Epoch: 3 [5760/60000 (10%)]\tLoss: 0.017785\nTrain Epoch: 3 [6400/60000 (11%)]\tLoss: 0.012487\nTrain Epoch: 3 [7040/60000 (12%)]\tLoss: 0.005026\nTrain Epoch: 3 [7680/60000 (13%)]\tLoss: 0.004177\nTrain Epoch: 3 [8320/60000 (14%)]\tLoss: 0.001953\nTrain Epoch: 3 [8960/60000 (15%)]\tLoss: 0.001892\nTrain Epoch: 3 [9600/60000 (16%)]\tLoss: 0.003034\nTrain Epoch: 3 [10240/60000 (17%)]\tLoss: 0.010195\nTrain Epoch: 3 [10880/60000 (18%)]\tLoss: 0.006455\nTrain Epoch: 3 [11520/60000 (19%)]\tLoss: 0.001581\nTrain Epoch: 3 [12160/60000 (20%)]\tLoss: 0.159295\nTrain Epoch: 3 [12800/60000 (21%)]\tLoss: 0.040355\nTrain Epoch: 3 [13440/60000 (22%)]\tLoss: 0.068944\nTrain Epoch: 3 [14080/60000 (23%)]\tLoss: 0.030196\nTrain Epoch: 3 [14720/60000 (25%)]\tLoss: 0.003007\nTrain Epoch: 3 [15360/60000 (26%)]\tLoss: 0.053638\nTrain Epoch: 3 [16000/60000 (27%)]\tLoss: 0.013261\nTrain Epoch: 3 [16640/60000 (28%)]\tLoss: 0.007955\nTrain Epoch: 3 [17280/60000 (29%)]\tLoss: 0.003011\nTrain Epoch: 3 [17920/60000 (30%)]\tLoss: 0.007640\nTrain Epoch: 3 [18560/60000 (31%)]\tLoss: 0.055195\nTrain Epoch: 3 [19200/60000 (32%)]\tLoss: 0.128923\nTrain Epoch: 3 [19840/60000 (33%)]\tLoss: 0.048820\nTrain Epoch: 3 [20480/60000 (34%)]\tLoss: 0.003376\nTrain Epoch: 3 [21120/60000 (35%)]\tLoss: 0.098348\nTrain Epoch: 3 [21760/60000 (36%)]\tLoss: 0.013039\nTrain Epoch: 3 [22400/60000 (37%)]\tLoss: 0.001537\nTrain Epoch: 3 [23040/60000 (38%)]\tLoss: 0.001650\nTrain Epoch: 3 [23680/60000 (39%)]\tLoss: 0.001204\nTrain Epoch: 3 [24320/60000 (41%)]\tLoss: 0.000951\nTrain Epoch: 3 [24960/60000 (42%)]\tLoss: 0.010871\nTrain Epoch: 3 [25600/60000 (43%)]\tLoss: 0.068402\nTrain Epoch: 3 [26240/60000 (44%)]\tLoss: 0.001981\nTrain Epoch: 3 [26880/60000 (45%)]\tLoss: 0.092606\nTrain Epoch: 3 [27520/60000 (46%)]\tLoss: 0.002798\nTrain Epoch: 3 [28160/60000 (47%)]\tLoss: 0.002582\nTrain Epoch: 3 [28800/60000 (48%)]\tLoss: 0.001977\nTrain Epoch: 3 [29440/60000 (49%)]\tLoss: 0.094212\nTrain Epoch: 3 [30080/60000 (50%)]\tLoss: 0.002556\nTrain Epoch: 3 [30720/60000 (51%)]\tLoss: 0.008891\nTrain Epoch: 3 [31360/60000 (52%)]\tLoss: 0.001651\nTrain Epoch: 3 [32000/60000 (53%)]\tLoss: 0.001014\nTrain Epoch: 3 [32640/60000 (54%)]\tLoss: 0.035663\nTrain Epoch: 3 [33280/60000 (55%)]\tLoss: 0.002191\nTrain Epoch: 3 [33920/60000 (57%)]\tLoss: 0.004289\nTrain Epoch: 3 [34560/60000 (58%)]\tLoss: 0.052664\nTrain Epoch: 3 [35200/60000 (59%)]\tLoss: 0.004212\nTrain Epoch: 3 [35840/60000 (60%)]\tLoss: 0.036116\nTrain Epoch: 3 [36480/60000 (61%)]\tLoss: 0.036297\nTrain Epoch: 3 [37120/60000 (62%)]\tLoss: 0.010904\nTrain Epoch: 3 [37760/60000 (63%)]\tLoss: 0.003564\nTrain Epoch: 3 [38400/60000 (64%)]\tLoss: 0.050133\nTrain Epoch: 3 [39040/60000 (65%)]\tLoss: 0.012209\nTrain Epoch: 3 [39680/60000 (66%)]\tLoss: 0.000881\nTrain Epoch: 3 [40320/60000 (67%)]\tLoss: 0.081812\nTrain Epoch: 3 [40960/60000 (68%)]\tLoss: 0.000890\nTrain Epoch: 3 [41600/60000 (69%)]\tLoss: 0.025801\nTrain Epoch: 3 [42240/60000 (70%)]\tLoss: 0.001586\nTrain Epoch: 3 [42880/60000 (71%)]\tLoss: 0.000873\nTrain Epoch: 3 [43520/60000 (72%)]\tLoss: 0.054376\nTrain Epoch: 3 [44160/60000 (74%)]\tLoss: 0.085006\nTrain Epoch: 3 [44800/60000 (75%)]\tLoss: 0.006084\nTrain Epoch: 3 [45440/60000 (76%)]\tLoss: 0.011692\nTrain Epoch: 3 [46080/60000 (77%)]\tLoss: 0.005950\nTrain Epoch: 3 [46720/60000 (78%)]\tLoss: 0.066314\nTrain Epoch: 3 [47360/60000 (79%)]\tLoss: 0.117669\nTrain Epoch: 3 [48000/60000 (80%)]\tLoss: 0.035859\nTrain Epoch: 3 [48640/60000 (81%)]\tLoss: 0.034860\nTrain Epoch: 3 [49280/60000 (82%)]\tLoss: 0.004861\nTrain Epoch: 3 [49920/60000 (83%)]\tLoss: 0.215828\nTrain Epoch: 3 [50560/60000 (84%)]\tLoss: 0.038957\nTrain Epoch: 3 [51200/60000 (85%)]\tLoss: 0.002910\nTrain Epoch: 3 [51840/60000 (86%)]\tLoss: 0.027677\nTrain Epoch: 3 [52480/60000 (87%)]\tLoss: 0.007691\nTrain Epoch: 3 [53120/60000 (88%)]\tLoss: 0.040408\nTrain Epoch: 3 [53760/60000 (90%)]\tLoss: 0.006226\nTrain Epoch: 3 [54400/60000 (91%)]\tLoss: 0.007342\nTrain Epoch: 3 [55040/60000 (92%)]\tLoss: 0.004826\nTrain Epoch: 3 [55680/60000 (93%)]\tLoss: 0.007757\nTrain Epoch: 3 [56320/60000 (94%)]\tLoss: 0.006584\nTrain Epoch: 3 [56960/60000 (95%)]\tLoss: 0.000576\nTrain Epoch: 3 [57600/60000 (96%)]\tLoss: 0.001806\nTrain Epoch: 3 [58240/60000 (97%)]\tLoss: 0.006036\nTrain Epoch: 3 [58880/60000 (98%)]\tLoss: 0.107218\nTrain Epoch: 3 [59520/60000 (99%)]\tLoss: 0.005951\n\nTest set: Average loss: 0.0000, Accuracy: 9932/10000 (99%)\n\nTrain Epoch: 4 [0/60000 (0%)]\tLoss: 0.006187\nTrain Epoch: 4 [640/60000 (1%)]\tLoss: 0.008526\nTrain Epoch: 4 [1280/60000 (2%)]\tLoss: 0.000675\nTrain Epoch: 4 [1920/60000 (3%)]\tLoss: 0.008540\nTrain Epoch: 4 [2560/60000 (4%)]\tLoss: 0.059127\nTrain Epoch: 4 [3200/60000 (5%)]\tLoss: 0.003802\nTrain Epoch: 4 [3840/60000 (6%)]\tLoss: 0.017609\nTrain Epoch: 4 [4480/60000 (7%)]\tLoss: 0.043319\nTrain Epoch: 4 [5120/60000 (9%)]\tLoss: 0.000966\nTrain Epoch: 4 [5760/60000 (10%)]\tLoss: 0.017167\nTrain Epoch: 4 [6400/60000 (11%)]\tLoss: 0.073196\nTrain Epoch: 4 [7040/60000 (12%)]\tLoss: 0.001819\nTrain Epoch: 4 [7680/60000 (13%)]\tLoss: 0.023707\nTrain Epoch: 4 [8320/60000 (14%)]\tLoss: 0.003055\nTrain Epoch: 4 [8960/60000 (15%)]\tLoss: 0.001573\nTrain Epoch: 4 [9600/60000 (16%)]\tLoss: 0.028514\nTrain Epoch: 4 [10240/60000 (17%)]\tLoss: 0.051199\nTrain Epoch: 4 [10880/60000 (18%)]\tLoss: 0.095405\nTrain Epoch: 4 [11520/60000 (19%)]\tLoss: 0.004930\nTrain Epoch: 4 [12160/60000 (20%)]\tLoss: 0.003691\nTrain Epoch: 4 [12800/60000 (21%)]\tLoss: 0.001386\nTrain Epoch: 4 [13440/60000 (22%)]\tLoss: 0.012147\nTrain Epoch: 4 [14080/60000 (23%)]\tLoss: 0.001127\nTrain Epoch: 4 [14720/60000 (25%)]\tLoss: 0.001704\nTrain Epoch: 4 [15360/60000 (26%)]\tLoss: 0.061200\nTrain Epoch: 4 [16000/60000 (27%)]\tLoss: 0.014545\nTrain Epoch: 4 [16640/60000 (28%)]\tLoss: 0.018640\nTrain Epoch: 4 [17280/60000 (29%)]\tLoss: 0.001203\nTrain Epoch: 4 [17920/60000 (30%)]\tLoss: 0.000620\nTrain Epoch: 4 [18560/60000 (31%)]\tLoss: 0.007283\nTrain Epoch: 4 [19200/60000 (32%)]\tLoss: 0.007646\nTrain Epoch: 4 [19840/60000 (33%)]\tLoss: 0.002784\nTrain Epoch: 4 [20480/60000 (34%)]\tLoss: 0.008086\nTrain Epoch: 4 [21120/60000 (35%)]\tLoss: 0.010493\nTrain Epoch: 4 [21760/60000 (36%)]\tLoss: 0.001510\nTrain Epoch: 4 [22400/60000 (37%)]\tLoss: 0.013722\nTrain Epoch: 4 [23040/60000 (38%)]\tLoss: 0.021354\nTrain Epoch: 4 [23680/60000 (39%)]\tLoss: 0.000874\nTrain Epoch: 4 [24320/60000 (41%)]\tLoss: 0.065825\nTrain Epoch: 4 [24960/60000 (42%)]\tLoss: 0.012598\nTrain Epoch: 4 [25600/60000 (43%)]\tLoss: 0.012606\nTrain Epoch: 4 [26240/60000 (44%)]\tLoss: 0.001221\nTrain Epoch: 4 [26880/60000 (45%)]\tLoss: 0.109092\nTrain Epoch: 4 [27520/60000 (46%)]\tLoss: 0.056147\nTrain Epoch: 4 [28160/60000 (47%)]\tLoss: 0.002104\nTrain Epoch: 4 [28800/60000 (48%)]\tLoss: 0.000326\nTrain Epoch: 4 [29440/60000 (49%)]\tLoss: 0.062471\nTrain Epoch: 4 [30080/60000 (50%)]\tLoss: 0.006425\nTrain Epoch: 4 [30720/60000 (51%)]\tLoss: 0.001430\nTrain Epoch: 4 [31360/60000 (52%)]\tLoss: 0.020443\nTrain Epoch: 4 [32000/60000 (53%)]\tLoss: 0.005401\nTrain Epoch: 4 [32640/60000 (54%)]\tLoss: 0.000633\nTrain Epoch: 4 [33280/60000 (55%)]\tLoss: 0.013960\nTrain Epoch: 4 [33920/60000 (57%)]\tLoss: 0.002135\nTrain Epoch: 4 [34560/60000 (58%)]\tLoss: 0.051865\nTrain Epoch: 4 [35200/60000 (59%)]\tLoss: 0.000791\nTrain Epoch: 4 [35840/60000 (60%)]\tLoss: 0.000416\nTrain Epoch: 4 [36480/60000 (61%)]\tLoss: 0.000935\nTrain Epoch: 4 [37120/60000 (62%)]\tLoss: 0.003594\nTrain Epoch: 4 [37760/60000 (63%)]\tLoss: 0.037022\nTrain Epoch: 4 [38400/60000 (64%)]\tLoss: 0.039236\nTrain Epoch: 4 [39040/60000 (65%)]\tLoss: 0.000676\nTrain Epoch: 4 [39680/60000 (66%)]\tLoss: 0.022213\nTrain Epoch: 4 [40320/60000 (67%)]\tLoss: 0.214204\nTrain Epoch: 4 [40960/60000 (68%)]\tLoss: 0.000948\nTrain Epoch: 4 [41600/60000 (69%)]\tLoss: 0.003946\nTrain Epoch: 4 [42240/60000 (70%)]\tLoss: 0.001486\nTrain Epoch: 4 [42880/60000 (71%)]\tLoss: 0.009921\nTrain Epoch: 4 [43520/60000 (72%)]\tLoss: 0.008216\nTrain Epoch: 4 [44160/60000 (74%)]\tLoss: 0.001383\nTrain Epoch: 4 [44800/60000 (75%)]\tLoss: 0.003444\nTrain Epoch: 4 [45440/60000 (76%)]\tLoss: 0.028020\nTrain Epoch: 4 [46080/60000 (77%)]\tLoss: 0.007491\nTrain Epoch: 4 [46720/60000 (78%)]\tLoss: 0.003847\nTrain Epoch: 4 [47360/60000 (79%)]\tLoss: 0.000668\nTrain Epoch: 4 [48000/60000 (80%)]\tLoss: 0.001219\nTrain Epoch: 4 [48640/60000 (81%)]\tLoss: 0.000701\nTrain Epoch: 4 [49280/60000 (82%)]\tLoss: 0.000748\nTrain Epoch: 4 [49920/60000 (83%)]\tLoss: 0.000612\nTrain Epoch: 4 [50560/60000 (84%)]\tLoss: 0.017759\nTrain Epoch: 4 [51200/60000 (85%)]\tLoss: 0.079330\nTrain Epoch: 4 [51840/60000 (86%)]\tLoss: 0.003203\nTrain Epoch: 4 [52480/60000 (87%)]\tLoss: 0.000783\nTrain Epoch: 4 [53120/60000 (88%)]\tLoss: 0.012505\nTrain Epoch: 4 [53760/60000 (90%)]\tLoss: 0.000429\nTrain Epoch: 4 [54400/60000 (91%)]\tLoss: 0.016085\nTrain Epoch: 4 [55040/60000 (92%)]\tLoss: 0.006600\nTrain Epoch: 4 [55680/60000 (93%)]\tLoss: 0.008059\nTrain Epoch: 4 [56320/60000 (94%)]\tLoss: 0.002753\nTrain Epoch: 4 [56960/60000 (95%)]\tLoss: 0.001331\nTrain Epoch: 4 [57600/60000 (96%)]\tLoss: 0.033350\nTrain Epoch: 4 [58240/60000 (97%)]\tLoss: 0.001533\nTrain Epoch: 4 [58880/60000 (98%)]\tLoss: 0.000838\nTrain Epoch: 4 [59520/60000 (99%)]\tLoss: 0.000653\n\nTest set: Average loss: 0.0000, Accuracy: 9931/10000 (99%)\n\nTrain Epoch: 5 [0/60000 (0%)]\tLoss: 0.022751\nTrain Epoch: 5 [640/60000 (1%)]\tLoss: 0.001051\nTrain Epoch: 5 [1280/60000 (2%)]\tLoss: 0.082072\nTrain Epoch: 5 [1920/60000 (3%)]\tLoss: 0.003636\nTrain Epoch: 5 [2560/60000 (4%)]\tLoss: 0.004756\nTrain Epoch: 5 [3200/60000 (5%)]\tLoss: 0.001776\nTrain Epoch: 5 [3840/60000 (6%)]\tLoss: 0.000376\nTrain Epoch: 5 [4480/60000 (7%)]\tLoss: 0.001164\nTrain Epoch: 5 [5120/60000 (9%)]\tLoss: 0.007932\nTrain Epoch: 5 [5760/60000 (10%)]\tLoss: 0.001023\nTrain Epoch: 5 [6400/60000 (11%)]\tLoss: 0.005473\nTrain Epoch: 5 [7040/60000 (12%)]\tLoss: 0.145729\nTrain Epoch: 5 [7680/60000 (13%)]\tLoss: 0.005466\nTrain Epoch: 5 [8320/60000 (14%)]\tLoss: 0.000902\nTrain Epoch: 5 [8960/60000 (15%)]\tLoss: 0.001279\nTrain Epoch: 5 [9600/60000 (16%)]\tLoss: 0.000876\nTrain Epoch: 5 [10240/60000 (17%)]\tLoss: 0.052943\nTrain Epoch: 5 [10880/60000 (18%)]\tLoss: 0.001041\nTrain Epoch: 5 [11520/60000 (19%)]\tLoss: 0.001239\nTrain Epoch: 5 [12160/60000 (20%)]\tLoss: 0.041232\nTrain Epoch: 5 [12800/60000 (21%)]\tLoss: 0.003246\nTrain Epoch: 5 [13440/60000 (22%)]\tLoss: 0.000811\nTrain Epoch: 5 [14080/60000 (23%)]\tLoss: 0.015766\nTrain Epoch: 5 [14720/60000 (25%)]\tLoss: 0.007054\nTrain Epoch: 5 [15360/60000 (26%)]\tLoss: 0.006926\nTrain Epoch: 5 [16000/60000 (27%)]\tLoss: 0.010827\nTrain Epoch: 5 [16640/60000 (28%)]\tLoss: 0.016776\nTrain Epoch: 5 [17280/60000 (29%)]\tLoss: 0.001209\nTrain Epoch: 5 [17920/60000 (30%)]\tLoss: 0.002889\nTrain Epoch: 5 [18560/60000 (31%)]\tLoss: 0.000557\nTrain Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000482\nTrain Epoch: 5 [19840/60000 (33%)]\tLoss: 0.000601\nTrain Epoch: 5 [20480/60000 (34%)]\tLoss: 0.004307\nTrain Epoch: 5 [21120/60000 (35%)]\tLoss: 0.000446\nTrain Epoch: 5 [21760/60000 (36%)]\tLoss: 0.026668\nTrain Epoch: 5 [22400/60000 (37%)]\tLoss: 0.000963\nTrain Epoch: 5 [23040/60000 (38%)]\tLoss: 0.012604\nTrain Epoch: 5 [23680/60000 (39%)]\tLoss: 0.000182\nTrain Epoch: 5 [24320/60000 (41%)]\tLoss: 0.016700\nTrain Epoch: 5 [24960/60000 (42%)]\tLoss: 0.002042\nTrain Epoch: 5 [25600/60000 (43%)]\tLoss: 0.000786\nTrain Epoch: 5 [26240/60000 (44%)]\tLoss: 0.002838\nTrain Epoch: 5 [26880/60000 (45%)]\tLoss: 0.016614\nTrain Epoch: 5 [27520/60000 (46%)]\tLoss: 0.007081\nTrain Epoch: 5 [28160/60000 (47%)]\tLoss: 0.000323\nTrain Epoch: 5 [28800/60000 (48%)]\tLoss: 0.013225\nTrain Epoch: 5 [29440/60000 (49%)]\tLoss: 0.000367\nTrain Epoch: 5 [30080/60000 (50%)]\tLoss: 0.001674\nTrain Epoch: 5 [30720/60000 (51%)]\tLoss: 0.019293\nTrain Epoch: 5 [31360/60000 (52%)]\tLoss: 0.001046\nTrain Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000851\nTrain Epoch: 5 [32640/60000 (54%)]\tLoss: 0.000320\nTrain Epoch: 5 [33280/60000 (55%)]\tLoss: 0.000604\nTrain Epoch: 5 [33920/60000 (57%)]\tLoss: 0.030200\nTrain Epoch: 5 [34560/60000 (58%)]\tLoss: 0.008921\nTrain Epoch: 5 [35200/60000 (59%)]\tLoss: 0.000748\nTrain Epoch: 5 [35840/60000 (60%)]\tLoss: 0.000397\nTrain Epoch: 5 [36480/60000 (61%)]\tLoss: 0.033070\nTrain Epoch: 5 [37120/60000 (62%)]\tLoss: 0.030592\nTrain Epoch: 5 [37760/60000 (63%)]\tLoss: 0.021318\nTrain Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000812\nTrain Epoch: 5 [39040/60000 (65%)]\tLoss: 0.000532\nTrain Epoch: 5 [39680/60000 (66%)]\tLoss: 0.006557\nTrain Epoch: 5 [40320/60000 (67%)]\tLoss: 0.036599\nTrain Epoch: 5 [40960/60000 (68%)]\tLoss: 0.003029\nTrain Epoch: 5 [41600/60000 (69%)]\tLoss: 0.000863\nTrain Epoch: 5 [42240/60000 (70%)]\tLoss: 0.000767\nTrain Epoch: 5 [42880/60000 (71%)]\tLoss: 0.010134\nTrain Epoch: 5 [43520/60000 (72%)]\tLoss: 0.001471\nTrain Epoch: 5 [44160/60000 (74%)]\tLoss: 0.000661\nTrain Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000458\nTrain Epoch: 5 [45440/60000 (76%)]\tLoss: 0.001383\nTrain Epoch: 5 [46080/60000 (77%)]\tLoss: 0.000504\nTrain Epoch: 5 [46720/60000 (78%)]\tLoss: 0.001707\nTrain Epoch: 5 [47360/60000 (79%)]\tLoss: 0.001161\nTrain Epoch: 5 [48000/60000 (80%)]\tLoss: 0.000226\nTrain Epoch: 5 [48640/60000 (81%)]\tLoss: 0.001421\nTrain Epoch: 5 [49280/60000 (82%)]\tLoss: 0.002382\nTrain Epoch: 5 [49920/60000 (83%)]\tLoss: 0.001291\nTrain Epoch: 5 [50560/60000 (84%)]\tLoss: 0.000531\nTrain Epoch: 5 [51200/60000 (85%)]\tLoss: 0.002253\nTrain Epoch: 5 [51840/60000 (86%)]\tLoss: 0.001940\nTrain Epoch: 5 [52480/60000 (87%)]\tLoss: 0.000374\nTrain Epoch: 5 [53120/60000 (88%)]\tLoss: 0.000218\nTrain Epoch: 5 [53760/60000 (90%)]\tLoss: 0.000194\nTrain Epoch: 5 [54400/60000 (91%)]\tLoss: 0.000377\nTrain Epoch: 5 [55040/60000 (92%)]\tLoss: 0.004778\nTrain Epoch: 5 [55680/60000 (93%)]\tLoss: 0.003647\nTrain Epoch: 5 [56320/60000 (94%)]\tLoss: 0.000233\nTrain Epoch: 5 [56960/60000 (95%)]\tLoss: 0.000877\nTrain Epoch: 5 [57600/60000 (96%)]\tLoss: 0.009046\nTrain Epoch: 5 [58240/60000 (97%)]\tLoss: 0.001803\nTrain Epoch: 5 [58880/60000 (98%)]\tLoss: 0.002509\nTrain Epoch: 5 [59520/60000 (99%)]\tLoss: 0.000481\n\nTest set: Average loss: 0.0000, Accuracy: 9945/10000 (99%)\n\nTrain Epoch: 6 [0/60000 (0%)]\tLoss: 0.005169\nTrain Epoch: 6 [640/60000 (1%)]\tLoss: 0.000228\nTrain Epoch: 6 [1280/60000 (2%)]\tLoss: 0.002538\nTrain Epoch: 6 [1920/60000 (3%)]\tLoss: 0.000471\nTrain Epoch: 6 [2560/60000 (4%)]\tLoss: 0.009279\nTrain Epoch: 6 [3200/60000 (5%)]\tLoss: 0.000213\nTrain Epoch: 6 [3840/60000 (6%)]\tLoss: 0.000276\nTrain Epoch: 6 [4480/60000 (7%)]\tLoss: 0.001734\nTrain Epoch: 6 [5120/60000 (9%)]\tLoss: 0.000741\nTrain Epoch: 6 [5760/60000 (10%)]\tLoss: 0.000314\nTrain Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000435\nTrain Epoch: 6 [7040/60000 (12%)]\tLoss: 0.001274\nTrain Epoch: 6 [7680/60000 (13%)]\tLoss: 0.000100\nTrain Epoch: 6 [8320/60000 (14%)]\tLoss: 0.001352\nTrain Epoch: 6 [8960/60000 (15%)]\tLoss: 0.007227\nTrain Epoch: 6 [9600/60000 (16%)]\tLoss: 0.001029\nTrain Epoch: 6 [10240/60000 (17%)]\tLoss: 0.004214\nTrain Epoch: 6 [10880/60000 (18%)]\tLoss: 0.002688\nTrain Epoch: 6 [11520/60000 (19%)]\tLoss: 0.000132\nTrain Epoch: 6 [12160/60000 (20%)]\tLoss: 0.002892\nTrain Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000352\nTrain Epoch: 6 [13440/60000 (22%)]\tLoss: 0.000632\nTrain Epoch: 6 [14080/60000 (23%)]\tLoss: 0.000187\nTrain Epoch: 6 [14720/60000 (25%)]\tLoss: 0.000169\nTrain Epoch: 6 [15360/60000 (26%)]\tLoss: 0.000262\nTrain Epoch: 6 [16000/60000 (27%)]\tLoss: 0.000484\nTrain Epoch: 6 [16640/60000 (28%)]\tLoss: 0.000992\nTrain Epoch: 6 [17280/60000 (29%)]\tLoss: 0.039195\nTrain Epoch: 6 [17920/60000 (30%)]\tLoss: 0.000175\nTrain Epoch: 6 [18560/60000 (31%)]\tLoss: 0.001638\nTrain Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000623\nTrain Epoch: 6 [19840/60000 (33%)]\tLoss: 0.000501\nTrain Epoch: 6 [20480/60000 (34%)]\tLoss: 0.006072\nTrain Epoch: 6 [21120/60000 (35%)]\tLoss: 0.001278\nTrain Epoch: 6 [21760/60000 (36%)]\tLoss: 0.001761\nTrain Epoch: 6 [22400/60000 (37%)]\tLoss: 0.000238\nTrain Epoch: 6 [23040/60000 (38%)]\tLoss: 0.003833\nTrain Epoch: 6 [23680/60000 (39%)]\tLoss: 0.044279\nTrain Epoch: 6 [24320/60000 (41%)]\tLoss: 0.001134\nTrain Epoch: 6 [24960/60000 (42%)]\tLoss: 0.001144\nTrain Epoch: 6 [25600/60000 (43%)]\tLoss: 0.024975\nTrain Epoch: 6 [26240/60000 (44%)]\tLoss: 0.000375\nTrain Epoch: 6 [26880/60000 (45%)]\tLoss: 0.001629\nTrain Epoch: 6 [27520/60000 (46%)]\tLoss: 0.008639\nTrain Epoch: 6 [28160/60000 (47%)]\tLoss: 0.004926\nTrain Epoch: 6 [28800/60000 (48%)]\tLoss: 0.063986\nTrain Epoch: 6 [29440/60000 (49%)]\tLoss: 0.000165\nTrain Epoch: 6 [30080/60000 (50%)]\tLoss: 0.000208\nTrain Epoch: 6 [30720/60000 (51%)]\tLoss: 0.000324\nTrain Epoch: 6 [31360/60000 (52%)]\tLoss: 0.000104\nTrain Epoch: 6 [32000/60000 (53%)]\tLoss: 0.004792\nTrain Epoch: 6 [32640/60000 (54%)]\tLoss: 0.011674\nTrain Epoch: 6 [33280/60000 (55%)]\tLoss: 0.000172\nTrain Epoch: 6 [33920/60000 (57%)]\tLoss: 0.000304\nTrain Epoch: 6 [34560/60000 (58%)]\tLoss: 0.005735\nTrain Epoch: 6 [35200/60000 (59%)]\tLoss: 0.001205\nTrain Epoch: 6 [35840/60000 (60%)]\tLoss: 0.000082\nTrain Epoch: 6 [36480/60000 (61%)]\tLoss: 0.005877\nTrain Epoch: 6 [37120/60000 (62%)]\tLoss: 0.000520\nTrain Epoch: 6 [37760/60000 (63%)]\tLoss: 0.002261\nTrain Epoch: 6 [38400/60000 (64%)]\tLoss: 0.001388\nTrain Epoch: 6 [39040/60000 (65%)]\tLoss: 0.000253\nTrain Epoch: 6 [39680/60000 (66%)]\tLoss: 0.000517\nTrain Epoch: 6 [40320/60000 (67%)]\tLoss: 0.001902\nTrain Epoch: 6 [40960/60000 (68%)]\tLoss: 0.002719\nTrain Epoch: 6 [41600/60000 (69%)]\tLoss: 0.000939\nTrain Epoch: 6 [42240/60000 (70%)]\tLoss: 0.002588\nTrain Epoch: 6 [42880/60000 (71%)]\tLoss: 0.000327\nTrain Epoch: 6 [43520/60000 (72%)]\tLoss: 0.000348\nTrain Epoch: 6 [44160/60000 (74%)]\tLoss: 0.000927\nTrain Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000168\nTrain Epoch: 6 [45440/60000 (76%)]\tLoss: 0.024452\nTrain Epoch: 6 [46080/60000 (77%)]\tLoss: 0.000145\nTrain Epoch: 6 [46720/60000 (78%)]\tLoss: 0.000512\nTrain Epoch: 6 [47360/60000 (79%)]\tLoss: 0.000367\nTrain Epoch: 6 [48000/60000 (80%)]\tLoss: 0.000169\nTrain Epoch: 6 [48640/60000 (81%)]\tLoss: 0.000314\nTrain Epoch: 6 [49280/60000 (82%)]\tLoss: 0.001086\nTrain Epoch: 6 [49920/60000 (83%)]\tLoss: 0.000679\nTrain Epoch: 6 [50560/60000 (84%)]\tLoss: 0.000198\nTrain Epoch: 6 [51200/60000 (85%)]\tLoss: 0.001114\nTrain Epoch: 6 [51840/60000 (86%)]\tLoss: 0.001792\nTrain Epoch: 6 [52480/60000 (87%)]\tLoss: 0.000443\nTrain Epoch: 6 [53120/60000 (88%)]\tLoss: 0.003508\nTrain Epoch: 6 [53760/60000 (90%)]\tLoss: 0.011905\nTrain Epoch: 6 [54400/60000 (91%)]\tLoss: 0.004315\nTrain Epoch: 6 [55040/60000 (92%)]\tLoss: 0.002513\nTrain Epoch: 6 [55680/60000 (93%)]\tLoss: 0.000229\nTrain Epoch: 6 [56320/60000 (94%)]\tLoss: 0.000519\nTrain Epoch: 6 [56960/60000 (95%)]\tLoss: 0.003471\nTrain Epoch: 6 [57600/60000 (96%)]\tLoss: 0.009090\nTrain Epoch: 6 [58240/60000 (97%)]\tLoss: 0.003295\nTrain Epoch: 6 [58880/60000 (98%)]\tLoss: 0.081491\nTrain Epoch: 6 [59520/60000 (99%)]\tLoss: 0.005704\n\nTest set: Average loss: 0.0000, Accuracy: 9956/10000 (100%)\n\nTrain Epoch: 7 [0/60000 (0%)]\tLoss: 0.000956\nTrain Epoch: 7 [640/60000 (1%)]\tLoss: 0.000769\nTrain Epoch: 7 [1280/60000 (2%)]\tLoss: 0.000324\nTrain Epoch: 7 [1920/60000 (3%)]\tLoss: 0.000185\nTrain Epoch: 7 [2560/60000 (4%)]\tLoss: 0.002851\nTrain Epoch: 7 [3200/60000 (5%)]\tLoss: 0.000545\nTrain Epoch: 7 [3840/60000 (6%)]\tLoss: 0.000285\nTrain Epoch: 7 [4480/60000 (7%)]\tLoss: 0.002882\nTrain Epoch: 7 [5120/60000 (9%)]\tLoss: 0.001319\nTrain Epoch: 7 [5760/60000 (10%)]\tLoss: 0.000430\nTrain Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000257\nTrain Epoch: 7 [7040/60000 (12%)]\tLoss: 0.005566\nTrain Epoch: 7 [7680/60000 (13%)]\tLoss: 0.000541\nTrain Epoch: 7 [8320/60000 (14%)]\tLoss: 0.001334\nTrain Epoch: 7 [8960/60000 (15%)]\tLoss: 0.000492\nTrain Epoch: 7 [9600/60000 (16%)]\tLoss: 0.015185\nTrain Epoch: 7 [10240/60000 (17%)]\tLoss: 0.000154\nTrain Epoch: 7 [10880/60000 (18%)]\tLoss: 0.001147\nTrain Epoch: 7 [11520/60000 (19%)]\tLoss: 0.000468\nTrain Epoch: 7 [12160/60000 (20%)]\tLoss: 0.000105\nTrain Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003042\nTrain Epoch: 7 [13440/60000 (22%)]\tLoss: 0.000139\nTrain Epoch: 7 [14080/60000 (23%)]\tLoss: 0.013326\nTrain Epoch: 7 [14720/60000 (25%)]\tLoss: 0.000239\nTrain Epoch: 7 [15360/60000 (26%)]\tLoss: 0.011662\nTrain Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000636\nTrain Epoch: 7 [16640/60000 (28%)]\tLoss: 0.004140\nTrain Epoch: 7 [17280/60000 (29%)]\tLoss: 0.000293\nTrain Epoch: 7 [17920/60000 (30%)]\tLoss: 0.020206\nTrain Epoch: 7 [18560/60000 (31%)]\tLoss: 0.000254\nTrain Epoch: 7 [19200/60000 (32%)]\tLoss: 0.004049\nTrain Epoch: 7 [19840/60000 (33%)]\tLoss: 0.003167\nTrain Epoch: 7 [20480/60000 (34%)]\tLoss: 0.004491\nTrain Epoch: 7 [21120/60000 (35%)]\tLoss: 0.000323\nTrain Epoch: 7 [21760/60000 (36%)]\tLoss: 0.010404\nTrain Epoch: 7 [22400/60000 (37%)]\tLoss: 0.000189\nTrain Epoch: 7 [23040/60000 (38%)]\tLoss: 0.000056\nTrain Epoch: 7 [23680/60000 (39%)]\tLoss: 0.000604\nTrain Epoch: 7 [24320/60000 (41%)]\tLoss: 0.001784\nTrain Epoch: 7 [24960/60000 (42%)]\tLoss: 0.000264\nTrain Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000207\nTrain Epoch: 7 [26240/60000 (44%)]\tLoss: 0.001013\nTrain Epoch: 7 [26880/60000 (45%)]\tLoss: 0.000217\nTrain Epoch: 7 [27520/60000 (46%)]\tLoss: 0.003094\nTrain Epoch: 7 [28160/60000 (47%)]\tLoss: 0.000311\nTrain Epoch: 7 [28800/60000 (48%)]\tLoss: 0.000172\nTrain Epoch: 7 [29440/60000 (49%)]\tLoss: 0.000521\nTrain Epoch: 7 [30080/60000 (50%)]\tLoss: 0.000099\nTrain Epoch: 7 [30720/60000 (51%)]\tLoss: 0.012971\nTrain Epoch: 7 [31360/60000 (52%)]\tLoss: 0.115190\nTrain Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000515\nTrain Epoch: 7 [32640/60000 (54%)]\tLoss: 0.003663\nTrain Epoch: 7 [33280/60000 (55%)]\tLoss: 0.000111\nTrain Epoch: 7 [33920/60000 (57%)]\tLoss: 0.000136\nTrain Epoch: 7 [34560/60000 (58%)]\tLoss: 0.000077\nTrain Epoch: 7 [35200/60000 (59%)]\tLoss: 0.001230\nTrain Epoch: 7 [35840/60000 (60%)]\tLoss: 0.000578\nTrain Epoch: 7 [36480/60000 (61%)]\tLoss: 0.000080\nTrain Epoch: 7 [37120/60000 (62%)]\tLoss: 0.000150\nTrain Epoch: 7 [37760/60000 (63%)]\tLoss: 0.000584\nTrain Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000902\nTrain Epoch: 7 [39040/60000 (65%)]\tLoss: 0.000128\nTrain Epoch: 7 [39680/60000 (66%)]\tLoss: 0.000231\nTrain Epoch: 7 [40320/60000 (67%)]\tLoss: 0.001872\nTrain Epoch: 7 [40960/60000 (68%)]\tLoss: 0.002532\nTrain Epoch: 7 [41600/60000 (69%)]\tLoss: 0.014150\nTrain Epoch: 7 [42240/60000 (70%)]\tLoss: 0.000197\nTrain Epoch: 7 [42880/60000 (71%)]\tLoss: 0.002476\nTrain Epoch: 7 [43520/60000 (72%)]\tLoss: 0.000365\nTrain Epoch: 7 [44160/60000 (74%)]\tLoss: 0.000512\nTrain Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000070\nTrain Epoch: 7 [45440/60000 (76%)]\tLoss: 0.000650\nTrain Epoch: 7 [46080/60000 (77%)]\tLoss: 0.000207\nTrain Epoch: 7 [46720/60000 (78%)]\tLoss: 0.003637\nTrain Epoch: 7 [47360/60000 (79%)]\tLoss: 0.008848\nTrain Epoch: 7 [48000/60000 (80%)]\tLoss: 0.000461\nTrain Epoch: 7 [48640/60000 (81%)]\tLoss: 0.000373\nTrain Epoch: 7 [49280/60000 (82%)]\tLoss: 0.000431\nTrain Epoch: 7 [49920/60000 (83%)]\tLoss: 0.000145\nTrain Epoch: 7 [50560/60000 (84%)]\tLoss: 0.001880\nTrain Epoch: 7 [51200/60000 (85%)]\tLoss: 0.001380\nTrain Epoch: 7 [51840/60000 (86%)]\tLoss: 0.000578\nTrain Epoch: 7 [52480/60000 (87%)]\tLoss: 0.000458\nTrain Epoch: 7 [53120/60000 (88%)]\tLoss: 0.000113\nTrain Epoch: 7 [53760/60000 (90%)]\tLoss: 0.001258\nTrain Epoch: 7 [54400/60000 (91%)]\tLoss: 0.003552\nTrain Epoch: 7 [55040/60000 (92%)]\tLoss: 0.002454\nTrain Epoch: 7 [55680/60000 (93%)]\tLoss: 0.005753\nTrain Epoch: 7 [56320/60000 (94%)]\tLoss: 0.002635\nTrain Epoch: 7 [56960/60000 (95%)]\tLoss: 0.000921\nTrain Epoch: 7 [57600/60000 (96%)]\tLoss: 0.001237\nTrain Epoch: 7 [58240/60000 (97%)]\tLoss: 0.000173\nTrain Epoch: 7 [58880/60000 (98%)]\tLoss: 0.000420\nTrain Epoch: 7 [59520/60000 (99%)]\tLoss: 0.011128\n\nTest set: Average loss: 0.0000, Accuracy: 9954/10000 (100%)\n\nTrain Epoch: 8 [0/60000 (0%)]\tLoss: 0.000852\nTrain Epoch: 8 [640/60000 (1%)]\tLoss: 0.000061\nTrain Epoch: 8 [1280/60000 (2%)]\tLoss: 0.000403\nTrain Epoch: 8 [1920/60000 (3%)]\tLoss: 0.009581\nTrain Epoch: 8 [2560/60000 (4%)]\tLoss: 0.000259\nTrain Epoch: 8 [3200/60000 (5%)]\tLoss: 0.000312\nTrain Epoch: 8 [3840/60000 (6%)]\tLoss: 0.000346\nTrain Epoch: 8 [4480/60000 (7%)]\tLoss: 0.027960\nTrain Epoch: 8 [5120/60000 (9%)]\tLoss: 0.000218\nTrain Epoch: 8 [5760/60000 (10%)]\tLoss: 0.000239\nTrain Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000610\nTrain Epoch: 8 [7040/60000 (12%)]\tLoss: 0.000616\nTrain Epoch: 8 [7680/60000 (13%)]\tLoss: 0.000783\nTrain Epoch: 8 [8320/60000 (14%)]\tLoss: 0.100376\nTrain Epoch: 8 [8960/60000 (15%)]\tLoss: 0.004004\nTrain Epoch: 8 [9600/60000 (16%)]\tLoss: 0.003868\nTrain Epoch: 8 [10240/60000 (17%)]\tLoss: 0.000168\nTrain Epoch: 8 [10880/60000 (18%)]\tLoss: 0.000363\nTrain Epoch: 8 [11520/60000 (19%)]\tLoss: 0.000507\nTrain Epoch: 8 [12160/60000 (20%)]\tLoss: 0.000188\nTrain Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000410\nTrain Epoch: 8 [13440/60000 (22%)]\tLoss: 0.008169\nTrain Epoch: 8 [14080/60000 (23%)]\tLoss: 0.001651\nTrain Epoch: 8 [14720/60000 (25%)]\tLoss: 0.000125\nTrain Epoch: 8 [15360/60000 (26%)]\tLoss: 0.002857\nTrain Epoch: 8 [16000/60000 (27%)]\tLoss: 0.001681\nTrain Epoch: 8 [16640/60000 (28%)]\tLoss: 0.000249\nTrain Epoch: 8 [17280/60000 (29%)]\tLoss: 0.001552\nTrain Epoch: 8 [17920/60000 (30%)]\tLoss: 0.003137\nTrain Epoch: 8 [18560/60000 (31%)]\tLoss: 0.000190\nTrain Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000191\nTrain Epoch: 8 [19840/60000 (33%)]\tLoss: 0.000066\nTrain Epoch: 8 [20480/60000 (34%)]\tLoss: 0.000107\nTrain Epoch: 8 [21120/60000 (35%)]\tLoss: 0.001608\nTrain Epoch: 8 [21760/60000 (36%)]\tLoss: 0.003759\nTrain Epoch: 8 [22400/60000 (37%)]\tLoss: 0.060792\nTrain Epoch: 8 [23040/60000 (38%)]\tLoss: 0.002391\nTrain Epoch: 8 [23680/60000 (39%)]\tLoss: 0.000710\nTrain Epoch: 8 [24320/60000 (41%)]\tLoss: 0.004296\nTrain Epoch: 8 [24960/60000 (42%)]\tLoss: 0.001285\nTrain Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000990\nTrain Epoch: 8 [26240/60000 (44%)]\tLoss: 0.000053\nTrain Epoch: 8 [26880/60000 (45%)]\tLoss: 0.035077\nTrain Epoch: 8 [27520/60000 (46%)]\tLoss: 0.000430\nTrain Epoch: 8 [28160/60000 (47%)]\tLoss: 0.001869\nTrain Epoch: 8 [28800/60000 (48%)]\tLoss: 0.002272\nTrain Epoch: 8 [29440/60000 (49%)]\tLoss: 0.001691\nTrain Epoch: 8 [30080/60000 (50%)]\tLoss: 0.001328\nTrain Epoch: 8 [30720/60000 (51%)]\tLoss: 0.079418\nTrain Epoch: 8 [31360/60000 (52%)]\tLoss: 0.000642\nTrain Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000163\nTrain Epoch: 8 [32640/60000 (54%)]\tLoss: 0.001530\nTrain Epoch: 8 [33280/60000 (55%)]\tLoss: 0.000203\nTrain Epoch: 8 [33920/60000 (57%)]\tLoss: 0.000201\nTrain Epoch: 8 [34560/60000 (58%)]\tLoss: 0.015657\nTrain Epoch: 8 [35200/60000 (59%)]\tLoss: 0.013680\nTrain Epoch: 8 [35840/60000 (60%)]\tLoss: 0.000806\nTrain Epoch: 8 [36480/60000 (61%)]\tLoss: 0.000276\nTrain Epoch: 8 [37120/60000 (62%)]\tLoss: 0.001030\nTrain Epoch: 8 [37760/60000 (63%)]\tLoss: 0.000406\nTrain Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000266\nTrain Epoch: 8 [39040/60000 (65%)]\tLoss: 0.000298\nTrain Epoch: 8 [39680/60000 (66%)]\tLoss: 0.000395\nTrain Epoch: 8 [40320/60000 (67%)]\tLoss: 0.000135\nTrain Epoch: 8 [40960/60000 (68%)]\tLoss: 0.001635\nTrain Epoch: 8 [41600/60000 (69%)]\tLoss: 0.000211\nTrain Epoch: 8 [42240/60000 (70%)]\tLoss: 0.000348\nTrain Epoch: 8 [42880/60000 (71%)]\tLoss: 0.021893\nTrain Epoch: 8 [43520/60000 (72%)]\tLoss: 0.002224\nTrain Epoch: 8 [44160/60000 (74%)]\tLoss: 0.000149\nTrain Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000147\nTrain Epoch: 8 [45440/60000 (76%)]\tLoss: 0.000075\nTrain Epoch: 8 [46080/60000 (77%)]\tLoss: 0.000167\nTrain Epoch: 8 [46720/60000 (78%)]\tLoss: 0.000726\nTrain Epoch: 8 [47360/60000 (79%)]\tLoss: 0.000216\nTrain Epoch: 8 [48000/60000 (80%)]\tLoss: 0.000258\nTrain Epoch: 8 [48640/60000 (81%)]\tLoss: 0.000988\nTrain Epoch: 8 [49280/60000 (82%)]\tLoss: 0.000444\nTrain Epoch: 8 [49920/60000 (83%)]\tLoss: 0.000177\nTrain Epoch: 8 [50560/60000 (84%)]\tLoss: 0.000078\nTrain Epoch: 8 [51200/60000 (85%)]\tLoss: 0.003556\nTrain Epoch: 8 [51840/60000 (86%)]\tLoss: 0.001693\nTrain Epoch: 8 [52480/60000 (87%)]\tLoss: 0.000475\nTrain Epoch: 8 [53120/60000 (88%)]\tLoss: 0.000277\nTrain Epoch: 8 [53760/60000 (90%)]\tLoss: 0.015444\nTrain Epoch: 8 [54400/60000 (91%)]\tLoss: 0.002667\nTrain Epoch: 8 [55040/60000 (92%)]\tLoss: 0.000876\nTrain Epoch: 8 [55680/60000 (93%)]\tLoss: 0.001558\nTrain Epoch: 8 [56320/60000 (94%)]\tLoss: 0.004035\nTrain Epoch: 8 [56960/60000 (95%)]\tLoss: 0.001856\nTrain Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000502\nTrain Epoch: 8 [58240/60000 (97%)]\tLoss: 0.000158\nTrain Epoch: 8 [58880/60000 (98%)]\tLoss: 0.005110\nTrain Epoch: 8 [59520/60000 (99%)]\tLoss: 0.000247\n\nTest set: Average loss: 0.0000, Accuracy: 9957/10000 (100%)\n\nTrain Epoch: 9 [0/60000 (0%)]\tLoss: 0.000464\nTrain Epoch: 9 [640/60000 (1%)]\tLoss: 0.000132\nTrain Epoch: 9 [1280/60000 (2%)]\tLoss: 0.002939\nTrain Epoch: 9 [1920/60000 (3%)]\tLoss: 0.000153\nTrain Epoch: 9 [2560/60000 (4%)]\tLoss: 0.000357\nTrain Epoch: 9 [3200/60000 (5%)]\tLoss: 0.000186\nTrain Epoch: 9 [3840/60000 (6%)]\tLoss: 0.000367\nTrain Epoch: 9 [4480/60000 (7%)]\tLoss: 0.000363\nTrain Epoch: 9 [5120/60000 (9%)]\tLoss: 0.005981\nTrain Epoch: 9 [5760/60000 (10%)]\tLoss: 0.024534\nTrain Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000316\nTrain Epoch: 9 [7040/60000 (12%)]\tLoss: 0.016294\nTrain Epoch: 9 [7680/60000 (13%)]\tLoss: 0.000146\nTrain Epoch: 9 [8320/60000 (14%)]\tLoss: 0.000177\nTrain Epoch: 9 [8960/60000 (15%)]\tLoss: 0.000580\nTrain Epoch: 9 [9600/60000 (16%)]\tLoss: 0.000791\nTrain Epoch: 9 [10240/60000 (17%)]\tLoss: 0.001020\nTrain Epoch: 9 [10880/60000 (18%)]\tLoss: 0.000062\nTrain Epoch: 9 [11520/60000 (19%)]\tLoss: 0.000459\nTrain Epoch: 9 [12160/60000 (20%)]\tLoss: 0.001017\nTrain Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000313\nTrain Epoch: 9 [13440/60000 (22%)]\tLoss: 0.000083\nTrain Epoch: 9 [14080/60000 (23%)]\tLoss: 0.000048\nTrain Epoch: 9 [14720/60000 (25%)]\tLoss: 0.001443\nTrain Epoch: 9 [15360/60000 (26%)]\tLoss: 0.006001\nTrain Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000690\nTrain Epoch: 9 [16640/60000 (28%)]\tLoss: 0.000034\nTrain Epoch: 9 [17280/60000 (29%)]\tLoss: 0.001675\nTrain Epoch: 9 [17920/60000 (30%)]\tLoss: 0.000056\nTrain Epoch: 9 [18560/60000 (31%)]\tLoss: 0.000046\nTrain Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000034\nTrain Epoch: 9 [19840/60000 (33%)]\tLoss: 0.001063\nTrain Epoch: 9 [20480/60000 (34%)]\tLoss: 0.000394\nTrain Epoch: 9 [21120/60000 (35%)]\tLoss: 0.000644\nTrain Epoch: 9 [21760/60000 (36%)]\tLoss: 0.001100\nTrain Epoch: 9 [22400/60000 (37%)]\tLoss: 0.000065\nTrain Epoch: 9 [23040/60000 (38%)]\tLoss: 0.010817\nTrain Epoch: 9 [23680/60000 (39%)]\tLoss: 0.000285\nTrain Epoch: 9 [24320/60000 (41%)]\tLoss: 0.000115\nTrain Epoch: 9 [24960/60000 (42%)]\tLoss: 0.000937\nTrain Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000043\nTrain Epoch: 9 [26240/60000 (44%)]\tLoss: 0.000036\nTrain Epoch: 9 [26880/60000 (45%)]\tLoss: 0.001367\nTrain Epoch: 9 [27520/60000 (46%)]\tLoss: 0.018125\nTrain Epoch: 9 [28160/60000 (47%)]\tLoss: 0.008653\nTrain Epoch: 9 [28800/60000 (48%)]\tLoss: 0.000801\nTrain Epoch: 9 [29440/60000 (49%)]\tLoss: 0.000198\nTrain Epoch: 9 [30080/60000 (50%)]\tLoss: 0.000194\nTrain Epoch: 9 [30720/60000 (51%)]\tLoss: 0.000373\nTrain Epoch: 9 [31360/60000 (52%)]\tLoss: 0.024264\nTrain Epoch: 9 [32000/60000 (53%)]\tLoss: 0.006544\nTrain Epoch: 9 [32640/60000 (54%)]\tLoss: 0.002889\nTrain Epoch: 9 [33280/60000 (55%)]\tLoss: 0.001742\nTrain Epoch: 9 [33920/60000 (57%)]\tLoss: 0.001902\nTrain Epoch: 9 [34560/60000 (58%)]\tLoss: 0.000775\nTrain Epoch: 9 [35200/60000 (59%)]\tLoss: 0.000089\nTrain Epoch: 9 [35840/60000 (60%)]\tLoss: 0.000320\nTrain Epoch: 9 [36480/60000 (61%)]\tLoss: 0.000065\nTrain Epoch: 9 [37120/60000 (62%)]\tLoss: 0.001383\nTrain Epoch: 9 [37760/60000 (63%)]\tLoss: 0.000995\nTrain Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001770\nTrain Epoch: 9 [39040/60000 (65%)]\tLoss: 0.000100\nTrain Epoch: 9 [39680/60000 (66%)]\tLoss: 0.000275\nTrain Epoch: 9 [40320/60000 (67%)]\tLoss: 0.000057\nTrain Epoch: 9 [40960/60000 (68%)]\tLoss: 0.000076\nTrain Epoch: 9 [41600/60000 (69%)]\tLoss: 0.002193\nTrain Epoch: 9 [42240/60000 (70%)]\tLoss: 0.000705\nTrain Epoch: 9 [42880/60000 (71%)]\tLoss: 0.001158\nTrain Epoch: 9 [43520/60000 (72%)]\tLoss: 0.000032\nTrain Epoch: 9 [44160/60000 (74%)]\tLoss: 0.000218\nTrain Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000743\nTrain Epoch: 9 [45440/60000 (76%)]\tLoss: 0.006837\nTrain Epoch: 9 [46080/60000 (77%)]\tLoss: 0.000191\nTrain Epoch: 9 [46720/60000 (78%)]\tLoss: 0.000103\nTrain Epoch: 9 [47360/60000 (79%)]\tLoss: 0.000136\nTrain Epoch: 9 [48000/60000 (80%)]\tLoss: 0.000030\nTrain Epoch: 9 [48640/60000 (81%)]\tLoss: 0.000564\nTrain Epoch: 9 [49280/60000 (82%)]\tLoss: 0.000455\nTrain Epoch: 9 [49920/60000 (83%)]\tLoss: 0.001125\nTrain Epoch: 9 [50560/60000 (84%)]\tLoss: 0.000498\nTrain Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000441\nTrain Epoch: 9 [51840/60000 (86%)]\tLoss: 0.000158\nTrain Epoch: 9 [52480/60000 (87%)]\tLoss: 0.001025\nTrain Epoch: 9 [53120/60000 (88%)]\tLoss: 0.000184\nTrain Epoch: 9 [53760/60000 (90%)]\tLoss: 0.003773\nTrain Epoch: 9 [54400/60000 (91%)]\tLoss: 0.000164\nTrain Epoch: 9 [55040/60000 (92%)]\tLoss: 0.000237\nTrain Epoch: 9 [55680/60000 (93%)]\tLoss: 0.000022\nTrain Epoch: 9 [56320/60000 (94%)]\tLoss: 0.001746\nTrain Epoch: 9 [56960/60000 (95%)]\tLoss: 0.020854\nTrain Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000106\nTrain Epoch: 9 [58240/60000 (97%)]\tLoss: 0.024799\nTrain Epoch: 9 [58880/60000 (98%)]\tLoss: 0.007636\nTrain Epoch: 9 [59520/60000 (99%)]\tLoss: 0.000194\n\nTest set: Average loss: 0.0000, Accuracy: 9953/10000 (100%)\n\nTrain Epoch: 10 [0/60000 (0%)]\tLoss: 0.002687\nTrain Epoch: 10 [640/60000 (1%)]\tLoss: 0.000131\nTrain Epoch: 10 [1280/60000 (2%)]\tLoss: 0.000182\nTrain Epoch: 10 [1920/60000 (3%)]\tLoss: 0.000064\nTrain Epoch: 10 [2560/60000 (4%)]\tLoss: 0.000019\nTrain Epoch: 10 [3200/60000 (5%)]\tLoss: 0.003468\nTrain Epoch: 10 [3840/60000 (6%)]\tLoss: 0.003065\nTrain Epoch: 10 [4480/60000 (7%)]\tLoss: 0.000741\nTrain Epoch: 10 [5120/60000 (9%)]\tLoss: 0.000337\nTrain Epoch: 10 [5760/60000 (10%)]\tLoss: 0.000296\nTrain Epoch: 10 [6400/60000 (11%)]\tLoss: 0.000192\nTrain Epoch: 10 [7040/60000 (12%)]\tLoss: 0.000046\nTrain Epoch: 10 [7680/60000 (13%)]\tLoss: 0.000121\nTrain Epoch: 10 [8320/60000 (14%)]\tLoss: 0.000199\nTrain Epoch: 10 [8960/60000 (15%)]\tLoss: 0.000017\nTrain Epoch: 10 [9600/60000 (16%)]\tLoss: 0.000143\nTrain Epoch: 10 [10240/60000 (17%)]\tLoss: 0.000332\nTrain Epoch: 10 [10880/60000 (18%)]\tLoss: 0.000101\nTrain Epoch: 10 [11520/60000 (19%)]\tLoss: 0.000238\nTrain Epoch: 10 [12160/60000 (20%)]\tLoss: 0.000184\nTrain Epoch: 10 [12800/60000 (21%)]\tLoss: 0.000502\nTrain Epoch: 10 [13440/60000 (22%)]\tLoss: 0.000208\nTrain Epoch: 10 [14080/60000 (23%)]\tLoss: 0.000242\nTrain Epoch: 10 [14720/60000 (25%)]\tLoss: 0.000233\nTrain Epoch: 10 [15360/60000 (26%)]\tLoss: 0.000083\nTrain Epoch: 10 [16000/60000 (27%)]\tLoss: 0.000596\nTrain Epoch: 10 [16640/60000 (28%)]\tLoss: 0.000188\nTrain Epoch: 10 [17280/60000 (29%)]\tLoss: 0.004204\nTrain Epoch: 10 [17920/60000 (30%)]\tLoss: 0.000190\nTrain Epoch: 10 [18560/60000 (31%)]\tLoss: 0.028576\nTrain Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000669\nTrain Epoch: 10 [19840/60000 (33%)]\tLoss: 0.000117\nTrain Epoch: 10 [20480/60000 (34%)]\tLoss: 0.000130\nTrain Epoch: 10 [21120/60000 (35%)]\tLoss: 0.000725\nTrain Epoch: 10 [21760/60000 (36%)]\tLoss: 0.000151\nTrain Epoch: 10 [22400/60000 (37%)]\tLoss: 0.000721\nTrain Epoch: 10 [23040/60000 (38%)]\tLoss: 0.000896\nTrain Epoch: 10 [23680/60000 (39%)]\tLoss: 0.000182\nTrain Epoch: 10 [24320/60000 (41%)]\tLoss: 0.000629\nTrain Epoch: 10 [24960/60000 (42%)]\tLoss: 0.003989\nTrain Epoch: 10 [25600/60000 (43%)]\tLoss: 0.002341\nTrain Epoch: 10 [26240/60000 (44%)]\tLoss: 0.092888\nTrain Epoch: 10 [26880/60000 (45%)]\tLoss: 0.000326\nTrain Epoch: 10 [27520/60000 (46%)]\tLoss: 0.000094\nTrain Epoch: 10 [28160/60000 (47%)]\tLoss: 0.000066\nTrain Epoch: 10 [28800/60000 (48%)]\tLoss: 0.000503\nTrain Epoch: 10 [29440/60000 (49%)]\tLoss: 0.000048\nTrain Epoch: 10 [30080/60000 (50%)]\tLoss: 0.000026\nTrain Epoch: 10 [30720/60000 (51%)]\tLoss: 0.000187\nTrain Epoch: 10 [31360/60000 (52%)]\tLoss: 0.000043\nTrain Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000799\nTrain Epoch: 10 [32640/60000 (54%)]\tLoss: 0.000184\nTrain Epoch: 10 [33280/60000 (55%)]\tLoss: 0.000245\nTrain Epoch: 10 [33920/60000 (57%)]\tLoss: 0.018411\nTrain Epoch: 10 [34560/60000 (58%)]\tLoss: 0.000275\nTrain Epoch: 10 [35200/60000 (59%)]\tLoss: 0.000131\nTrain Epoch: 10 [35840/60000 (60%)]\tLoss: 0.000090\nTrain Epoch: 10 [36480/60000 (61%)]\tLoss: 0.000057\nTrain Epoch: 10 [37120/60000 (62%)]\tLoss: 0.000028\nTrain Epoch: 10 [37760/60000 (63%)]\tLoss: 0.000047\nTrain Epoch: 10 [38400/60000 (64%)]\tLoss: 0.000184\nTrain Epoch: 10 [39040/60000 (65%)]\tLoss: 0.000101\nTrain Epoch: 10 [39680/60000 (66%)]\tLoss: 0.000910\nTrain Epoch: 10 [40320/60000 (67%)]\tLoss: 0.057880\nTrain Epoch: 10 [40960/60000 (68%)]\tLoss: 0.000540\nTrain Epoch: 10 [41600/60000 (69%)]\tLoss: 0.000451\nTrain Epoch: 10 [42240/60000 (70%)]\tLoss: 0.000484\nTrain Epoch: 10 [42880/60000 (71%)]\tLoss: 0.013880\nTrain Epoch: 10 [43520/60000 (72%)]\tLoss: 0.000350\nTrain Epoch: 10 [44160/60000 (74%)]\tLoss: 0.001645\nTrain Epoch: 10 [44800/60000 (75%)]\tLoss: 0.001460\nTrain Epoch: 10 [45440/60000 (76%)]\tLoss: 0.000792\nTrain Epoch: 10 [46080/60000 (77%)]\tLoss: 0.000097\nTrain Epoch: 10 [46720/60000 (78%)]\tLoss: 0.000095\nTrain Epoch: 10 [47360/60000 (79%)]\tLoss: 0.000154\nTrain Epoch: 10 [48000/60000 (80%)]\tLoss: 0.006874\nTrain Epoch: 10 [48640/60000 (81%)]\tLoss: 0.002666\nTrain Epoch: 10 [49280/60000 (82%)]\tLoss: 0.000114\nTrain Epoch: 10 [49920/60000 (83%)]\tLoss: 0.000181\nTrain Epoch: 10 [50560/60000 (84%)]\tLoss: 0.000105\nTrain Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000203\nTrain Epoch: 10 [51840/60000 (86%)]\tLoss: 0.000025\nTrain Epoch: 10 [52480/60000 (87%)]\tLoss: 0.000077\nTrain Epoch: 10 [53120/60000 (88%)]\tLoss: 0.000063\nTrain Epoch: 10 [53760/60000 (90%)]\tLoss: 0.000839\nTrain Epoch: 10 [54400/60000 (91%)]\tLoss: 0.000070\nTrain Epoch: 10 [55040/60000 (92%)]\tLoss: 0.000218\nTrain Epoch: 10 [55680/60000 (93%)]\tLoss: 0.000766\nTrain Epoch: 10 [56320/60000 (94%)]\tLoss: 0.000107\nTrain Epoch: 10 [56960/60000 (95%)]\tLoss: 0.000802\nTrain Epoch: 10 [57600/60000 (96%)]\tLoss: 0.000193\nTrain Epoch: 10 [58240/60000 (97%)]\tLoss: 0.000438\nTrain Epoch: 10 [58880/60000 (98%)]\tLoss: 0.000032\nTrain Epoch: 10 [59520/60000 (99%)]\tLoss: 0.000247\n\nTest set: Average loss: 0.0000, Accuracy: 9952/10000 (100%)\n\nTrain Epoch: 11 [0/60000 (0%)]\tLoss: 0.000087\nTrain Epoch: 11 [640/60000 (1%)]\tLoss: 0.000670\nTrain Epoch: 11 [1280/60000 (2%)]\tLoss: 0.000030\nTrain Epoch: 11 [1920/60000 (3%)]\tLoss: 0.000218\nTrain Epoch: 11 [2560/60000 (4%)]\tLoss: 0.001011\nTrain Epoch: 11 [3200/60000 (5%)]\tLoss: 0.000041\nTrain Epoch: 11 [3840/60000 (6%)]\tLoss: 0.000489\nTrain Epoch: 11 [4480/60000 (7%)]\tLoss: 0.095623\nTrain Epoch: 11 [5120/60000 (9%)]\tLoss: 0.000232\nTrain Epoch: 11 [5760/60000 (10%)]\tLoss: 0.001644\nTrain Epoch: 11 [6400/60000 (11%)]\tLoss: 0.018007\nTrain Epoch: 11 [7040/60000 (12%)]\tLoss: 0.000093\nTrain Epoch: 11 [7680/60000 (13%)]\tLoss: 0.003260\nTrain Epoch: 11 [8320/60000 (14%)]\tLoss: 0.036382\nTrain Epoch: 11 [8960/60000 (15%)]\tLoss: 0.000059\nTrain Epoch: 11 [9600/60000 (16%)]\tLoss: 0.000290\nTrain Epoch: 11 [10240/60000 (17%)]\tLoss: 0.001814\nTrain Epoch: 11 [10880/60000 (18%)]\tLoss: 0.000095\nTrain Epoch: 11 [11520/60000 (19%)]\tLoss: 0.000121\nTrain Epoch: 11 [12160/60000 (20%)]\tLoss: 0.003406\nTrain Epoch: 11 [12800/60000 (21%)]\tLoss: 0.006360\nTrain Epoch: 11 [13440/60000 (22%)]\tLoss: 0.000297\nTrain Epoch: 11 [14080/60000 (23%)]\tLoss: 0.000287\nTrain Epoch: 11 [14720/60000 (25%)]\tLoss: 0.000038\nTrain Epoch: 11 [15360/60000 (26%)]\tLoss: 0.000322\nTrain Epoch: 11 [16000/60000 (27%)]\tLoss: 0.000104\nTrain Epoch: 11 [16640/60000 (28%)]\tLoss: 0.000577\nTrain Epoch: 11 [17280/60000 (29%)]\tLoss: 0.001084\nTrain Epoch: 11 [17920/60000 (30%)]\tLoss: 0.064113\nTrain Epoch: 11 [18560/60000 (31%)]\tLoss: 0.000252\nTrain Epoch: 11 [19200/60000 (32%)]\tLoss: 0.000047\nTrain Epoch: 11 [19840/60000 (33%)]\tLoss: 0.000239\nTrain Epoch: 11 [20480/60000 (34%)]\tLoss: 0.151186\nTrain Epoch: 11 [21120/60000 (35%)]\tLoss: 0.000695\nTrain Epoch: 11 [21760/60000 (36%)]\tLoss: 0.000652\nTrain Epoch: 11 [22400/60000 (37%)]\tLoss: 0.000598\nTrain Epoch: 11 [23040/60000 (38%)]\tLoss: 0.000108\nTrain Epoch: 11 [23680/60000 (39%)]\tLoss: 0.000230\nTrain Epoch: 11 [24320/60000 (41%)]\tLoss: 0.000149\nTrain Epoch: 11 [24960/60000 (42%)]\tLoss: 0.004295\nTrain Epoch: 11 [25600/60000 (43%)]\tLoss: 0.000124\nTrain Epoch: 11 [26240/60000 (44%)]\tLoss: 0.000073\nTrain Epoch: 11 [26880/60000 (45%)]\tLoss: 0.000038\nTrain Epoch: 11 [27520/60000 (46%)]\tLoss: 0.000233\nTrain Epoch: 11 [28160/60000 (47%)]\tLoss: 0.000197\nTrain Epoch: 11 [28800/60000 (48%)]\tLoss: 0.016509\nTrain Epoch: 11 [29440/60000 (49%)]\tLoss: 0.000259\nTrain Epoch: 11 [30080/60000 (50%)]\tLoss: 0.000143\nTrain Epoch: 11 [30720/60000 (51%)]\tLoss: 0.043407\nTrain Epoch: 11 [31360/60000 (52%)]\tLoss: 0.000167\nTrain Epoch: 11 [32000/60000 (53%)]\tLoss: 0.000349\nTrain Epoch: 11 [32640/60000 (54%)]\tLoss: 0.000088\nTrain Epoch: 11 [33280/60000 (55%)]\tLoss: 0.001119\nTrain Epoch: 11 [33920/60000 (57%)]\tLoss: 0.003396\nTrain Epoch: 11 [34560/60000 (58%)]\tLoss: 0.000043\nTrain Epoch: 11 [35200/60000 (59%)]\tLoss: 0.000099\nTrain Epoch: 11 [35840/60000 (60%)]\tLoss: 0.000184\nTrain Epoch: 11 [36480/60000 (61%)]\tLoss: 0.000322\nTrain Epoch: 11 [37120/60000 (62%)]\tLoss: 0.000144\nTrain Epoch: 11 [37760/60000 (63%)]\tLoss: 0.000021\nTrain Epoch: 11 [38400/60000 (64%)]\tLoss: 0.000075\nTrain Epoch: 11 [39040/60000 (65%)]\tLoss: 0.001321\nTrain Epoch: 11 [39680/60000 (66%)]\tLoss: 0.000110\nTrain Epoch: 11 [40320/60000 (67%)]\tLoss: 0.000144\nTrain Epoch: 11 [40960/60000 (68%)]\tLoss: 0.000024\nTrain Epoch: 11 [41600/60000 (69%)]\tLoss: 0.000256\nTrain Epoch: 11 [42240/60000 (70%)]\tLoss: 0.004568\nTrain Epoch: 11 [42880/60000 (71%)]\tLoss: 0.000487\nTrain Epoch: 11 [43520/60000 (72%)]\tLoss: 0.001525\nTrain Epoch: 11 [44160/60000 (74%)]\tLoss: 0.000418\nTrain Epoch: 11 [44800/60000 (75%)]\tLoss: 0.046374\nTrain Epoch: 11 [45440/60000 (76%)]\tLoss: 0.000099\nTrain Epoch: 11 [46080/60000 (77%)]\tLoss: 0.010197\nTrain Epoch: 11 [46720/60000 (78%)]\tLoss: 0.000025\nTrain Epoch: 11 [47360/60000 (79%)]\tLoss: 0.001662\nTrain Epoch: 11 [48000/60000 (80%)]\tLoss: 0.006903\nTrain Epoch: 11 [48640/60000 (81%)]\tLoss: 0.036216\nTrain Epoch: 11 [49280/60000 (82%)]\tLoss: 0.001030\nTrain Epoch: 11 [49920/60000 (83%)]\tLoss: 0.000353\nTrain Epoch: 11 [50560/60000 (84%)]\tLoss: 0.000230\nTrain Epoch: 11 [51200/60000 (85%)]\tLoss: 0.001181\nTrain Epoch: 11 [51840/60000 (86%)]\tLoss: 0.000591\nTrain Epoch: 11 [52480/60000 (87%)]\tLoss: 0.000025\nTrain Epoch: 11 [53120/60000 (88%)]\tLoss: 0.000131\nTrain Epoch: 11 [53760/60000 (90%)]\tLoss: 0.012184\nTrain Epoch: 11 [54400/60000 (91%)]\tLoss: 0.000077\nTrain Epoch: 11 [55040/60000 (92%)]\tLoss: 0.000250\nTrain Epoch: 11 [55680/60000 (93%)]\tLoss: 0.000503\nTrain Epoch: 11 [56320/60000 (94%)]\tLoss: 0.000181\nTrain Epoch: 11 [56960/60000 (95%)]\tLoss: 0.003231\nTrain Epoch: 11 [57600/60000 (96%)]\tLoss: 0.001659\nTrain Epoch: 11 [58240/60000 (97%)]\tLoss: 0.000271\nTrain Epoch: 11 [58880/60000 (98%)]\tLoss: 0.002090\nTrain Epoch: 11 [59520/60000 (99%)]\tLoss: 0.002141\n\nTest set: Average loss: 0.0000, Accuracy: 9954/10000 (100%)\n\nTrain Epoch: 12 [0/60000 (0%)]\tLoss: 0.000166\nTrain Epoch: 12 [640/60000 (1%)]\tLoss: 0.000075\nTrain Epoch: 12 [1280/60000 (2%)]\tLoss: 0.000430\nTrain Epoch: 12 [1920/60000 (3%)]\tLoss: 0.000038\nTrain Epoch: 12 [2560/60000 (4%)]\tLoss: 0.000025\nTrain Epoch: 12 [3200/60000 (5%)]\tLoss: 0.004297\nTrain Epoch: 12 [3840/60000 (6%)]\tLoss: 0.001614\nTrain Epoch: 12 [4480/60000 (7%)]\tLoss: 0.000500\nTrain Epoch: 12 [5120/60000 (9%)]\tLoss: 0.000149\nTrain Epoch: 12 [5760/60000 (10%)]\tLoss: 0.000457\nTrain Epoch: 12 [6400/60000 (11%)]\tLoss: 0.003547\nTrain Epoch: 12 [7040/60000 (12%)]\tLoss: 0.000411\nTrain Epoch: 12 [7680/60000 (13%)]\tLoss: 0.001012\nTrain Epoch: 12 [8320/60000 (14%)]\tLoss: 0.000079\nTrain Epoch: 12 [8960/60000 (15%)]\tLoss: 0.000999\nTrain Epoch: 12 [9600/60000 (16%)]\tLoss: 0.000273\nTrain Epoch: 12 [10240/60000 (17%)]\tLoss: 0.000122\nTrain Epoch: 12 [10880/60000 (18%)]\tLoss: 0.015232\nTrain Epoch: 12 [11520/60000 (19%)]\tLoss: 0.001116\nTrain Epoch: 12 [12160/60000 (20%)]\tLoss: 0.002345\nTrain Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001347\nTrain Epoch: 12 [13440/60000 (22%)]\tLoss: 0.012714\nTrain Epoch: 12 [14080/60000 (23%)]\tLoss: 0.001621\nTrain Epoch: 12 [14720/60000 (25%)]\tLoss: 0.000564\nTrain Epoch: 12 [15360/60000 (26%)]\tLoss: 0.000836\nTrain Epoch: 12 [16000/60000 (27%)]\tLoss: 0.000495\nTrain Epoch: 12 [16640/60000 (28%)]\tLoss: 0.000098\nTrain Epoch: 12 [17280/60000 (29%)]\tLoss: 0.000055\nTrain Epoch: 12 [17920/60000 (30%)]\tLoss: 0.000046\nTrain Epoch: 12 [18560/60000 (31%)]\tLoss: 0.162901\nTrain Epoch: 12 [19200/60000 (32%)]\tLoss: 0.000186\nTrain Epoch: 12 [19840/60000 (33%)]\tLoss: 0.000545\nTrain Epoch: 12 [20480/60000 (34%)]\tLoss: 0.000284\nTrain Epoch: 12 [21120/60000 (35%)]\tLoss: 0.000480\nTrain Epoch: 12 [21760/60000 (36%)]\tLoss: 0.002381\nTrain Epoch: 12 [22400/60000 (37%)]\tLoss: 0.000031\nTrain Epoch: 12 [23040/60000 (38%)]\tLoss: 0.002959\nTrain Epoch: 12 [23680/60000 (39%)]\tLoss: 0.001357\nTrain Epoch: 12 [24320/60000 (41%)]\tLoss: 0.000290\nTrain Epoch: 12 [24960/60000 (42%)]\tLoss: 0.034963\nTrain Epoch: 12 [25600/60000 (43%)]\tLoss: 0.001224\nTrain Epoch: 12 [26240/60000 (44%)]\tLoss: 0.000271\nTrain Epoch: 12 [26880/60000 (45%)]\tLoss: 0.000110\nTrain Epoch: 12 [27520/60000 (46%)]\tLoss: 0.000121\nTrain Epoch: 12 [28160/60000 (47%)]\tLoss: 0.000170\nTrain Epoch: 12 [28800/60000 (48%)]\tLoss: 0.000050\nTrain Epoch: 12 [29440/60000 (49%)]\tLoss: 0.000071\nTrain Epoch: 12 [30080/60000 (50%)]\tLoss: 0.000133\nTrain Epoch: 12 [30720/60000 (51%)]\tLoss: 0.000694\nTrain Epoch: 12 [31360/60000 (52%)]\tLoss: 0.000073\nTrain Epoch: 12 [32000/60000 (53%)]\tLoss: 0.000415\nTrain Epoch: 12 [32640/60000 (54%)]\tLoss: 0.000067\nTrain Epoch: 12 [33280/60000 (55%)]\tLoss: 0.007765\nTrain Epoch: 12 [33920/60000 (57%)]\tLoss: 0.000321\nTrain Epoch: 12 [34560/60000 (58%)]\tLoss: 0.000078\nTrain Epoch: 12 [35200/60000 (59%)]\tLoss: 0.000088\nTrain Epoch: 12 [35840/60000 (60%)]\tLoss: 0.000105\nTrain Epoch: 12 [36480/60000 (61%)]\tLoss: 0.000057\nTrain Epoch: 12 [37120/60000 (62%)]\tLoss: 0.005437\nTrain Epoch: 12 [37760/60000 (63%)]\tLoss: 0.001921\nTrain Epoch: 12 [38400/60000 (64%)]\tLoss: 0.000173\nTrain Epoch: 12 [39040/60000 (65%)]\tLoss: 0.000298\nTrain Epoch: 12 [39680/60000 (66%)]\tLoss: 0.000076\nTrain Epoch: 12 [40320/60000 (67%)]\tLoss: 0.000205\nTrain Epoch: 12 [40960/60000 (68%)]\tLoss: 0.000206\nTrain Epoch: 12 [41600/60000 (69%)]\tLoss: 0.000179\nTrain Epoch: 12 [42240/60000 (70%)]\tLoss: 0.101819\nTrain Epoch: 12 [42880/60000 (71%)]\tLoss: 0.000077\nTrain Epoch: 12 [43520/60000 (72%)]\tLoss: 0.000045\nTrain Epoch: 12 [44160/60000 (74%)]\tLoss: 0.000055\nTrain Epoch: 12 [44800/60000 (75%)]\tLoss: 0.042766\nTrain Epoch: 12 [45440/60000 (76%)]\tLoss: 0.000138\nTrain Epoch: 12 [46080/60000 (77%)]\tLoss: 0.038786\nTrain Epoch: 12 [46720/60000 (78%)]\tLoss: 0.000360\nTrain Epoch: 12 [47360/60000 (79%)]\tLoss: 0.000233\nTrain Epoch: 12 [48000/60000 (80%)]\tLoss: 0.000097\nTrain Epoch: 12 [48640/60000 (81%)]\tLoss: 0.000337\nTrain Epoch: 12 [49280/60000 (82%)]\tLoss: 0.004996\nTrain Epoch: 12 [49920/60000 (83%)]\tLoss: 0.000573\nTrain Epoch: 12 [50560/60000 (84%)]\tLoss: 0.000341\nTrain Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000099\nTrain Epoch: 12 [51840/60000 (86%)]\tLoss: 0.001531\nTrain Epoch: 12 [52480/60000 (87%)]\tLoss: 0.000120\nTrain Epoch: 12 [53120/60000 (88%)]\tLoss: 0.002284\nTrain Epoch: 12 [53760/60000 (90%)]\tLoss: 0.000367\nTrain Epoch: 12 [54400/60000 (91%)]\tLoss: 0.000303\nTrain Epoch: 12 [55040/60000 (92%)]\tLoss: 0.000261\nTrain Epoch: 12 [55680/60000 (93%)]\tLoss: 0.000053\nTrain Epoch: 12 [56320/60000 (94%)]\tLoss: 0.000025\nTrain Epoch: 12 [56960/60000 (95%)]\tLoss: 0.000061\nTrain Epoch: 12 [57600/60000 (96%)]\tLoss: 0.002379\nTrain Epoch: 12 [58240/60000 (97%)]\tLoss: 0.000058\nTrain Epoch: 12 [58880/60000 (98%)]\tLoss: 0.000157\nTrain Epoch: 12 [59520/60000 (99%)]\tLoss: 0.000101\n\nTest set: Average loss: 0.0000, Accuracy: 9948/10000 (99%)\n\nTrain Epoch: 13 [0/60000 (0%)]\tLoss: 0.007909\nTrain Epoch: 13 [640/60000 (1%)]\tLoss: 0.002022\nTrain Epoch: 13 [1280/60000 (2%)]\tLoss: 0.000041\nTrain Epoch: 13 [1920/60000 (3%)]\tLoss: 0.000066\nTrain Epoch: 13 [2560/60000 (4%)]\tLoss: 0.000304\nTrain Epoch: 13 [3200/60000 (5%)]\tLoss: 0.000130\nTrain Epoch: 13 [3840/60000 (6%)]\tLoss: 0.005653\nTrain Epoch: 13 [4480/60000 (7%)]\tLoss: 0.007021\nTrain Epoch: 13 [5120/60000 (9%)]\tLoss: 0.000255\nTrain Epoch: 13 [5760/60000 (10%)]\tLoss: 0.000104\nTrain Epoch: 13 [6400/60000 (11%)]\tLoss: 0.000686\nTrain Epoch: 13 [7040/60000 (12%)]\tLoss: 0.000075\nTrain Epoch: 13 [7680/60000 (13%)]\tLoss: 0.000206\nTrain Epoch: 13 [8320/60000 (14%)]\tLoss: 0.127625\nTrain Epoch: 13 [8960/60000 (15%)]\tLoss: 0.000260\nTrain Epoch: 13 [9600/60000 (16%)]\tLoss: 0.000156\nTrain Epoch: 13 [10240/60000 (17%)]\tLoss: 0.000044\nTrain Epoch: 13 [10880/60000 (18%)]\tLoss: 0.000146\nTrain Epoch: 13 [11520/60000 (19%)]\tLoss: 0.000135\nTrain Epoch: 13 [12160/60000 (20%)]\tLoss: 0.001028\nTrain Epoch: 13 [12800/60000 (21%)]\tLoss: 0.000238\nTrain Epoch: 13 [13440/60000 (22%)]\tLoss: 0.000467\nTrain Epoch: 13 [14080/60000 (23%)]\tLoss: 0.009918\nTrain Epoch: 13 [14720/60000 (25%)]\tLoss: 0.000076\nTrain Epoch: 13 [15360/60000 (26%)]\tLoss: 0.001102\nTrain Epoch: 13 [16000/60000 (27%)]\tLoss: 0.000179\nTrain Epoch: 13 [16640/60000 (28%)]\tLoss: 0.001334\nTrain Epoch: 13 [17280/60000 (29%)]\tLoss: 0.000081\nTrain Epoch: 13 [17920/60000 (30%)]\tLoss: 0.000053\nTrain Epoch: 13 [18560/60000 (31%)]\tLoss: 0.000385\nTrain Epoch: 13 [19200/60000 (32%)]\tLoss: 0.000025\nTrain Epoch: 13 [19840/60000 (33%)]\tLoss: 0.002172\nTrain Epoch: 13 [20480/60000 (34%)]\tLoss: 0.019709\nTrain Epoch: 13 [21120/60000 (35%)]\tLoss: 0.000093\nTrain Epoch: 13 [21760/60000 (36%)]\tLoss: 0.000162\nTrain Epoch: 13 [22400/60000 (37%)]\tLoss: 0.000287\nTrain Epoch: 13 [23040/60000 (38%)]\tLoss: 0.000049\nTrain Epoch: 13 [23680/60000 (39%)]\tLoss: 0.000115\nTrain Epoch: 13 [24320/60000 (41%)]\tLoss: 0.000224\nTrain Epoch: 13 [24960/60000 (42%)]\tLoss: 0.013816\nTrain Epoch: 13 [25600/60000 (43%)]\tLoss: 0.000199\nTrain Epoch: 13 [26240/60000 (44%)]\tLoss: 0.000476\nTrain Epoch: 13 [26880/60000 (45%)]\tLoss: 0.000288\nTrain Epoch: 13 [27520/60000 (46%)]\tLoss: 0.000818\nTrain Epoch: 13 [28160/60000 (47%)]\tLoss: 0.000592\nTrain Epoch: 13 [28800/60000 (48%)]\tLoss: 0.000594\nTrain Epoch: 13 [29440/60000 (49%)]\tLoss: 0.000499\nTrain Epoch: 13 [30080/60000 (50%)]\tLoss: 0.000078\nTrain Epoch: 13 [30720/60000 (51%)]\tLoss: 0.000142\nTrain Epoch: 13 [31360/60000 (52%)]\tLoss: 0.000142\nTrain Epoch: 13 [32000/60000 (53%)]\tLoss: 0.000036\nTrain Epoch: 13 [32640/60000 (54%)]\tLoss: 0.005449\nTrain Epoch: 13 [33280/60000 (55%)]\tLoss: 0.001245\nTrain Epoch: 13 [33920/60000 (57%)]\tLoss: 0.007639\nTrain Epoch: 13 [34560/60000 (58%)]\tLoss: 0.000301\nTrain Epoch: 13 [35200/60000 (59%)]\tLoss: 0.000028\nTrain Epoch: 13 [35840/60000 (60%)]\tLoss: 0.000043\nTrain Epoch: 13 [36480/60000 (61%)]\tLoss: 0.000626\nTrain Epoch: 13 [37120/60000 (62%)]\tLoss: 0.000233\nTrain Epoch: 13 [37760/60000 (63%)]\tLoss: 0.000802\nTrain Epoch: 13 [38400/60000 (64%)]\tLoss: 0.000157\nTrain Epoch: 13 [39040/60000 (65%)]\tLoss: 0.000055\nTrain Epoch: 13 [39680/60000 (66%)]\tLoss: 0.000131\nTrain Epoch: 13 [40320/60000 (67%)]\tLoss: 0.000089\nTrain Epoch: 13 [40960/60000 (68%)]\tLoss: 0.003185\nTrain Epoch: 13 [41600/60000 (69%)]\tLoss: 0.007048\nTrain Epoch: 13 [42240/60000 (70%)]\tLoss: 0.000269\nTrain Epoch: 13 [42880/60000 (71%)]\tLoss: 0.001902\nTrain Epoch: 13 [43520/60000 (72%)]\tLoss: 0.000750\nTrain Epoch: 13 [44160/60000 (74%)]\tLoss: 0.000165\nTrain Epoch: 13 [44800/60000 (75%)]\tLoss: 0.000065\nTrain Epoch: 13 [45440/60000 (76%)]\tLoss: 0.000237\nTrain Epoch: 13 [46080/60000 (77%)]\tLoss: 0.000106\nTrain Epoch: 13 [46720/60000 (78%)]\tLoss: 0.000555\nTrain Epoch: 13 [47360/60000 (79%)]\tLoss: 0.000085\nTrain Epoch: 13 [48000/60000 (80%)]\tLoss: 0.011026\nTrain Epoch: 13 [48640/60000 (81%)]\tLoss: 0.000148\nTrain Epoch: 13 [49280/60000 (82%)]\tLoss: 0.000309\nTrain Epoch: 13 [49920/60000 (83%)]\tLoss: 0.000153\nTrain Epoch: 13 [50560/60000 (84%)]\tLoss: 0.018341\nTrain Epoch: 13 [51200/60000 (85%)]\tLoss: 0.029832\nTrain Epoch: 13 [51840/60000 (86%)]\tLoss: 0.000465\nTrain Epoch: 13 [52480/60000 (87%)]\tLoss: 0.000754\nTrain Epoch: 13 [53120/60000 (88%)]\tLoss: 0.000079\nTrain Epoch: 13 [53760/60000 (90%)]\tLoss: 0.000869\nTrain Epoch: 13 [54400/60000 (91%)]\tLoss: 0.000802\nTrain Epoch: 13 [55040/60000 (92%)]\tLoss: 0.007032\nTrain Epoch: 13 [55680/60000 (93%)]\tLoss: 0.000095\nTrain Epoch: 13 [56320/60000 (94%)]\tLoss: 0.000109\nTrain Epoch: 13 [56960/60000 (95%)]\tLoss: 0.000034\nTrain Epoch: 13 [57600/60000 (96%)]\tLoss: 0.014128\nTrain Epoch: 13 [58240/60000 (97%)]\tLoss: 0.000046\nTrain Epoch: 13 [58880/60000 (98%)]\tLoss: 0.000098\nTrain Epoch: 13 [59520/60000 (99%)]\tLoss: 0.030463\n\nTest set: Average loss: 0.0000, Accuracy: 9950/10000 (100%)\n\nTrain Epoch: 14 [0/60000 (0%)]\tLoss: 0.000125\nTrain Epoch: 14 [640/60000 (1%)]\tLoss: 0.000079\nTrain Epoch: 14 [1280/60000 (2%)]\tLoss: 0.024100\nTrain Epoch: 14 [1920/60000 (3%)]\tLoss: 0.000338\nTrain Epoch: 14 [2560/60000 (4%)]\tLoss: 0.010131\nTrain Epoch: 14 [3200/60000 (5%)]\tLoss: 0.000782\nTrain Epoch: 14 [3840/60000 (6%)]\tLoss: 0.002035\nTrain Epoch: 14 [4480/60000 (7%)]\tLoss: 0.004807\nTrain Epoch: 14 [5120/60000 (9%)]\tLoss: 0.013324\nTrain Epoch: 14 [5760/60000 (10%)]\tLoss: 0.000146\nTrain Epoch: 14 [6400/60000 (11%)]\tLoss: 0.017001\nTrain Epoch: 14 [7040/60000 (12%)]\tLoss: 0.000191\nTrain Epoch: 14 [7680/60000 (13%)]\tLoss: 0.000801\nTrain Epoch: 14 [8320/60000 (14%)]\tLoss: 0.154532\nTrain Epoch: 14 [8960/60000 (15%)]\tLoss: 0.003242\nTrain Epoch: 14 [9600/60000 (16%)]\tLoss: 0.000043\nTrain Epoch: 14 [10240/60000 (17%)]\tLoss: 0.002911\nTrain Epoch: 14 [10880/60000 (18%)]\tLoss: 0.000971\nTrain Epoch: 14 [11520/60000 (19%)]\tLoss: 0.000284\nTrain Epoch: 14 [12160/60000 (20%)]\tLoss: 0.002907\nTrain Epoch: 14 [12800/60000 (21%)]\tLoss: 0.000553\nTrain Epoch: 14 [13440/60000 (22%)]\tLoss: 0.004685\nTrain Epoch: 14 [14080/60000 (23%)]\tLoss: 0.004872\nTrain Epoch: 14 [14720/60000 (25%)]\tLoss: 0.000182\nTrain Epoch: 14 [15360/60000 (26%)]\tLoss: 0.032938\nTrain Epoch: 14 [16000/60000 (27%)]\tLoss: 0.008750\nTrain Epoch: 14 [16640/60000 (28%)]\tLoss: 0.000178\nTrain Epoch: 14 [17280/60000 (29%)]\tLoss: 0.000394\nTrain Epoch: 14 [17920/60000 (30%)]\tLoss: 0.000235\nTrain Epoch: 14 [18560/60000 (31%)]\tLoss: 0.000095\nTrain Epoch: 14 [19200/60000 (32%)]\tLoss: 0.000057\nTrain Epoch: 14 [19840/60000 (33%)]\tLoss: 0.000694\nTrain Epoch: 14 [20480/60000 (34%)]\tLoss: 0.000048\nTrain Epoch: 14 [21120/60000 (35%)]\tLoss: 0.000082\nTrain Epoch: 14 [21760/60000 (36%)]\tLoss: 0.006838\nTrain Epoch: 14 [22400/60000 (37%)]\tLoss: 0.000676\nTrain Epoch: 14 [23040/60000 (38%)]\tLoss: 0.004698\nTrain Epoch: 14 [23680/60000 (39%)]\tLoss: 0.000040\nTrain Epoch: 14 [24320/60000 (41%)]\tLoss: 0.000040\nTrain Epoch: 14 [24960/60000 (42%)]\tLoss: 0.000041\nTrain Epoch: 14 [25600/60000 (43%)]\tLoss: 0.000603\nTrain Epoch: 14 [26240/60000 (44%)]\tLoss: 0.000064\nTrain Epoch: 14 [26880/60000 (45%)]\tLoss: 0.000140\nTrain Epoch: 14 [27520/60000 (46%)]\tLoss: 0.001484\nTrain Epoch: 14 [28160/60000 (47%)]\tLoss: 0.000165\nTrain Epoch: 14 [28800/60000 (48%)]\tLoss: 0.000021\nTrain Epoch: 14 [29440/60000 (49%)]\tLoss: 0.000097\nTrain Epoch: 14 [30080/60000 (50%)]\tLoss: 0.000093\nTrain Epoch: 14 [30720/60000 (51%)]\tLoss: 0.000277\nTrain Epoch: 14 [31360/60000 (52%)]\tLoss: 0.001653\nTrain Epoch: 14 [32000/60000 (53%)]\tLoss: 0.000385\nTrain Epoch: 14 [32640/60000 (54%)]\tLoss: 0.000137\nTrain Epoch: 14 [33280/60000 (55%)]\tLoss: 0.000173\nTrain Epoch: 14 [33920/60000 (57%)]\tLoss: 0.000022\nTrain Epoch: 14 [34560/60000 (58%)]\tLoss: 0.000104\nTrain Epoch: 14 [35200/60000 (59%)]\tLoss: 0.001158\nTrain Epoch: 14 [35840/60000 (60%)]\tLoss: 0.000216\nTrain Epoch: 14 [36480/60000 (61%)]\tLoss: 0.000076\nTrain Epoch: 14 [37120/60000 (62%)]\tLoss: 0.000053\nTrain Epoch: 14 [37760/60000 (63%)]\tLoss: 0.000046\nTrain Epoch: 14 [38400/60000 (64%)]\tLoss: 0.000195\nTrain Epoch: 14 [39040/60000 (65%)]\tLoss: 0.000084\nTrain Epoch: 14 [39680/60000 (66%)]\tLoss: 0.000360\nTrain Epoch: 14 [40320/60000 (67%)]\tLoss: 0.000097\nTrain Epoch: 14 [40960/60000 (68%)]\tLoss: 0.000545\nTrain Epoch: 14 [41600/60000 (69%)]\tLoss: 0.005057\nTrain Epoch: 14 [42240/60000 (70%)]\tLoss: 0.000113\nTrain Epoch: 14 [42880/60000 (71%)]\tLoss: 0.011947\nTrain Epoch: 14 [43520/60000 (72%)]\tLoss: 0.000112\nTrain Epoch: 14 [44160/60000 (74%)]\tLoss: 0.004810\nTrain Epoch: 14 [44800/60000 (75%)]\tLoss: 0.000560\nTrain Epoch: 14 [45440/60000 (76%)]\tLoss: 0.006803\nTrain Epoch: 14 [46080/60000 (77%)]\tLoss: 0.003067\nTrain Epoch: 14 [46720/60000 (78%)]\tLoss: 0.003251\nTrain Epoch: 14 [47360/60000 (79%)]\tLoss: 0.002261\nTrain Epoch: 14 [48000/60000 (80%)]\tLoss: 0.000380\nTrain Epoch: 14 [48640/60000 (81%)]\tLoss: 0.000523\nTrain Epoch: 14 [49280/60000 (82%)]\tLoss: 0.000266\nTrain Epoch: 14 [49920/60000 (83%)]\tLoss: 0.000061\nTrain Epoch: 14 [50560/60000 (84%)]\tLoss: 0.000092\nTrain Epoch: 14 [51200/60000 (85%)]\tLoss: 0.000104\nTrain Epoch: 14 [51840/60000 (86%)]\tLoss: 0.000306\nTrain Epoch: 14 [52480/60000 (87%)]\tLoss: 0.000352\nTrain Epoch: 14 [53120/60000 (88%)]\tLoss: 0.000189\nTrain Epoch: 14 [53760/60000 (90%)]\tLoss: 0.000078\nTrain Epoch: 14 [54400/60000 (91%)]\tLoss: 0.000285\nTrain Epoch: 14 [55040/60000 (92%)]\tLoss: 0.000327\nTrain Epoch: 14 [55680/60000 (93%)]\tLoss: 0.000594\nTrain Epoch: 14 [56320/60000 (94%)]\tLoss: 0.000082\nTrain Epoch: 14 [56960/60000 (95%)]\tLoss: 0.000123\nTrain Epoch: 14 [57600/60000 (96%)]\tLoss: 0.000502\nTrain Epoch: 14 [58240/60000 (97%)]\tLoss: 0.001272\nTrain Epoch: 14 [58880/60000 (98%)]\tLoss: 0.000167\nTrain Epoch: 14 [59520/60000 (99%)]\tLoss: 0.001079\n\nTest set: Average loss: 0.0000, Accuracy: 9963/10000 (100%)\n\n","output_type":"stream"}]}]}